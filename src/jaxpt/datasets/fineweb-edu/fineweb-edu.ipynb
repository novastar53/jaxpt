{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce15e81-6f0d-4942-9ef9-e74a36361a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a07e7bc91a4b53aeb66af829c120cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/25.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4101d09c440488abb79fc730d9e38af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac21d83e81e7469d89986ae2b6442c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "local_dir =  \"data\" \n",
    "DATA_CACHE_DIR = os.path.join(Path(), local_dir)\n",
    "os.makedirs(DATA_CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# download the dataset\n",
    "dataset = load_dataset(\"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", split=\"train\", cache_dir=DATA_CACHE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fad3ed75-c2ed-4544-b2e9-0ec28799af4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sytem statistics:\n",
      "-----------------\n",
      "cpu count: 30\n",
      "\n",
      "dataset statistics\n",
      "------------------\n",
      "documents: 9,672,101\n",
      "docs_per_cpu: 322404\n",
      "processed 150,463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 546,527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1,045,739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1,535,576"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 2,059,108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 2,582,119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 3,106,877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 3,631,030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 4,153,166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 4,674,850"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 5,196,935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 5,719,124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 6,239,533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 6,758,199"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 7,247,007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 7,772,239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 8,266,824"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 8,793,236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 9,317,536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import multiprocessing\n",
    "#multiprocessing.set_start_method('fork')   \n",
    "import concurrent.futures as cf\n",
    "import numpy as np\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "print(f\"\"\"\n",
    "sytem statistics:\n",
    "-----------------\n",
    "cpu count: {num_cpus}\"\"\")\n",
    "total_docs = len(dataset)\n",
    "docs_per_cpu = int(math.ceil(total_docs/num_cpus))\n",
    "print(f\"\"\"\n",
    "dataset statistics\n",
    "------------------\n",
    "documents: {total_docs:,}\n",
    "docs_per_cpu: {docs_per_cpu}\"\"\")\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "def count_tokens(dataset, enc, idx):\n",
    "    tokens = enc.encode_ordinary(dataset[idx]['text'])\n",
    "    return 1\n",
    "\n",
    "f = partial(count_tokens, dataset, enc)\n",
    "\n",
    "\n",
    "with cf.ProcessPoolExecutor(max_workers = num_cpus) as ex:\n",
    "    start = time.time()\n",
    "    documents = 0\n",
    "    tokens = 0\n",
    "    \n",
    "    for result in ex.map(f, list(range(len(dataset))), chunksize=docs_per_cpu):\n",
    "        documents += 1\n",
    "        tokens += result\n",
    "        documents % 100000 and print(f\"processed {documents:,}\", end=\"\\r\")\n",
    "        \n",
    "    print(f\"Processed documents in {time.time()-start:0.2f} seconds\")\n",
    "    print(f\"Total tokens: {tokens:,}\")\n",
    "    print(f\"Total documents: {documents:,}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f9802fa-cb02-4f92-a39c-0a0d0cadd11f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: \n",
      "Exception ignored in: Exception ignored in: Exception ignored in: <function tqdm.__del__ at 0x7379a9f12700><function tqdm.__del__ at 0x7379a9f12700><function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: Exception ignored in: Traceback (most recent call last):\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: Exception ignored in: \n",
      "Exception ignored in: Exception ignored in: Exception ignored in: Exception ignored in: <function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: \n",
      "<function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: Exception ignored in: <function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: Exception ignored in: Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "<function tqdm.__del__ at 0x7379a9f12700><function tqdm.__del__ at 0x7379a9f12700><function tqdm.__del__ at 0x7379a9f12700><function tqdm.__del__ at 0x7379a9f12700>\n",
      "<function tqdm.__del__ at 0x7379a9f12700>\n",
      "Exception ignored in: Exception ignored in: <function tqdm.__del__ at 0x7379a9f12700>  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: \n",
      "<function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: Exception ignored in: <function tqdm.__del__ at 0x7379a9f12700>  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "<function tqdm.__del__ at 0x7379a9f12700><function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: \n",
      "\n",
      "Exception ignored in: \n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function tqdm.__del__ at 0x7379a9f12700>Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "\n",
      "<function tqdm.__del__ at 0x7379a9f12700>Exception ignored in: \n",
      "<function tqdm.__del__ at 0x7379a9f12700>    Exception ignored in: <function tqdm.__del__ at 0x7379a9f12700>\n",
      "Traceback (most recent call last):\n",
      "<function tqdm.__del__ at 0x7379a9f12700>Traceback (most recent call last):\n",
      "<function tqdm.__del__ at 0x7379a9f12700>\n",
      "Traceback (most recent call last):\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    <function tqdm.__del__ at 0x7379a9f12700><function tqdm.__del__ at 0x7379a9f12700>Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "Traceback (most recent call last):\n",
      "\n",
      "    \n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "<function tqdm.__del__ at 0x7379a9f12700>  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "self.close()<function tqdm.__del__ at 0x7379a9f12700>Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    <function tqdm.__del__ at 0x7379a9f12700>  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "self.close()Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "\n",
      "    \n",
      "Traceback (most recent call last):\n",
      "      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "\n",
      "self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "        \n",
      "    \n",
      "      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "Traceback (most recent call last):\n",
      "self.close()Traceback (most recent call last):\n",
      "      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "self.close()Traceback (most recent call last):\n",
      "self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    Traceback (most recent call last):\n",
      "\n",
      "\n",
      "\n",
      "self.close()self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "self.close()    self.close()    self.close()      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()    \n",
      "            self.close()\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "self.close()    \n",
      "\n",
      "\n",
      "    \n",
      "self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "    self.close()\n",
      "self.close()    self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "self.close()self.close()\n",
      "self.close()\n",
      "if self.disable:  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "\n",
      "              File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "if self.disable:    self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "        \n",
      "\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "\n",
      "if self.disable:\n",
      "\n",
      "\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "    if self.disable:self.close()\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "self.close()\n",
      "\n",
      "self.close()if self.disable:if self.disable:  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "          File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "          File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "\n",
      "        \n",
      "if self.disable:self.close()  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "    if self.disable:  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "\n",
      "\n",
      "        \n",
      "AttributeError      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "\n",
      "\n",
      "if self.disable:\n",
      "if self.disable:AttributeError    if self.disable:if self.disable:AttributeErrorif self.disable:    if self.disable:if self.disable:        if self.disable:\n",
      "  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "\n",
      "      File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "AttributeError\n",
      ":         if self.disable:if self.disable:AttributeError  File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "AttributeError    : \n",
      "\n",
      "\n",
      "if self.disable:: \n",
      "if self.disable:if self.disable:\n",
      "\n",
      "if self.disable:if self.disable:\n",
      "AttributeError:   File \"/home/ubuntu/train-gpt2-data/jaxpt/.venv/lib/python3.13/site-packages/tqdm/notebook.py\", line 273, in close\n",
      "AttributeError\n",
      "\n",
      "'tqdm' object has no attribute 'disable'    if self.disable:\n",
      "if self.disable:    'tqdm' object has no attribute 'disable'if self.disable:AttributeError: : 'tqdm' object has no attribute 'disable'AttributeErrorAttributeErrorAttributeError    \n",
      "AttributeError\n",
      "AttributeError\n",
      "\n",
      "\n",
      "AttributeError: AttributeErrorAttributeError    'tqdm' object has no attribute 'disable': \n",
      "if self.disable:AttributeError\n",
      "\n",
      "if self.disable:\n",
      "'tqdm' object has no attribute 'disable': \n",
      ": : if self.disable:'tqdm' object has no attribute 'disable'AttributeError: AttributeErrorAttributeError: AttributeError\n",
      ": : AttributeError'tqdm' object has no attribute 'disable': 'tqdm' object has no attribute 'disable': : if self.disable:\n",
      "AttributeError\n",
      "\n",
      "'tqdm' object has no attribute 'disable'AttributeError\n",
      "\n",
      "'tqdm' object has no attribute 'disable''tqdm' object has no attribute 'disable'AttributeError\n",
      "'tqdm' object has no attribute 'disable': : : : 'tqdm' object has no attribute 'disable''tqdm' object has no attribute 'disable'\n",
      ": 'tqdm' object has no attribute 'disable''tqdm' object has no attribute 'disable''tqdm' object has no attribute 'disable'\n",
      "AttributeError'tqdm' object has no attribute 'disable': \n",
      "AttributeError\n",
      "\n",
      ": 'tqdm' object has no attribute 'disable': AttributeError\n",
      "\n",
      "'tqdm' object has no attribute 'disable''tqdm' object has no attribute 'disable''tqdm' object has no attribute 'disable'\n",
      "'tqdm' object has no attribute 'disable'\n",
      "\n",
      "\n",
      "AttributeError: \n",
      "\n",
      "\n",
      "\n",
      ": 'tqdm' object has no attribute 'disable''tqdm' object has no attribute 'disable''tqdm' object has no attribute 'disable'\n",
      "'tqdm' object has no attribute 'disable''tqdm' object has no attribute 'disable': \n",
      ": \n",
      "\n",
      "'tqdm' object has no attribute 'disable'\n",
      "\n",
      "\n",
      "\n",
      "'tqdm' object has no attribute 'disable'\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m shards_written = \u001b[32m0\u001b[39m\n\u001b[32m     55\u001b[39m tokens_generated = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_cpus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocs_processed\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshards_written\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/concurrent/futures/process.py:617\u001b[39m, in \u001b[36m_chain_from_iterable_of_lists\u001b[39m\u001b[34m(iterable)\u001b[39m\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[32m    612\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[33;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[32m    614\u001b[39m \u001b[33;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[32m    615\u001b[39m \u001b[33;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[32m    616\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43melement\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.2-linux-x86_64-gnu/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "SHARD_SIZE = int(1e8)\n",
    "output_dir = \"shards\"\n",
    "\n",
    "def tokenize(docs_per_cpu, shard_size, n):\n",
    "    #print(shard_size, n)\n",
    "    import os\n",
    "    import gc\n",
    "    \n",
    "    from pathlib import Path\n",
    "    from datasets import load_dataset\n",
    "    import tiktoken\n",
    "    \n",
    "    # set up tokenizer\n",
    "    enc = tiktoken.get_encoding(\"gpt2\")\n",
    "    eot = enc._special_tokens['<|endoftext|>']\n",
    "    \n",
    "    # load the dataset\n",
    "    dataset = load_dataset(\"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", split=\"train\", cache_dir=os.path.join(Path(), \"data\"))\n",
    "\n",
    "    # create the np array\n",
    "    shard = np.array([eot]*shard_size)\n",
    "    shard_idx = 1\n",
    "\n",
    "    docs_processed = 0\n",
    "    shards = 0\n",
    "    tokens = 0\n",
    "    start = n*docs_per_cpu\n",
    "    if len(dataset) - (n*docs_per_cpu) < docs_per_cpu:\n",
    "        end = len(dataset)\n",
    "    else:\n",
    "        end = start + docs_per_cpu\n",
    "    #print(start, end)\n",
    "    for idx, d in enumerate(dataset[start:end]['text']):\n",
    "        #print(f\"{idx:,}\", end=\"\\r\")\n",
    "        new_tokens = enc.encode_ordinary(d)\n",
    "        tokens += len(new_tokens)\n",
    "        if shard_idx + len(new_tokens) > shard_size:\n",
    "            #np.savez(os.path.join(Path(), \"shards\", f\"fineweb_{n}_{shards}.npz\"), shard)\n",
    "            shard_idx = 1\n",
    "            shards += 1\n",
    "        else:\n",
    "            shard_idx += len(new_tokens)\n",
    "            shard[idx:idx+len(new_tokens)] = new_tokens\n",
    "        docs_processed += 1\n",
    "    return docs_processed, shards, tokens\n",
    "\n",
    "t = partial(tokenize, docs_per_cpu, SHARD_SIZE)\n",
    "\n",
    "\n",
    "with cf.ProcessPoolExecutor(max_workers = num_cpus) as ex:\n",
    "    start = time.time()\n",
    "    \n",
    "    docs_processed = 0\n",
    "    shards_written = 0\n",
    "    tokens_generated = 0\n",
    "    for d, s, t in ex.map(t, range(num_cpus)):\n",
    "        docs_processed += d\n",
    "        shards_written += s\n",
    "        tokens_generated += t\n",
    "        print(f\"docs: {d:,}, shards: {s:,}, tokens: {t:,}\")\n",
    "        \n",
    "    print(f\"Processed documents in {time.time()-start:.2f} seconds\")\n",
    "    assert(sum([r[0] for r in results]) == total_docs)\n",
    "    print(f\"total shards written: {shards_written:,}\")\n",
    "    print(f\"total tokens: {tokens_generated:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (jaxpt)",
   "language": "python",
   "name": "jaxpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caabad99",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08731b0",
   "metadata": {},
   "source": [
    "## Soft Mixture of Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6a698a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.nnx as nnx\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1317ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMoE(nnx.Module):\n",
    "    def __init__(self, n_experts, capacity, n_dim, rngs):\n",
    "        init = nnx.initializers.normal(stddev=0.02)\n",
    "        self.gate = nnx.Param(\n",
    "            init(rngs.default(), (n_experts, capacity, n_dim))\n",
    "        )\n",
    "        self.experts = nnx.Param(\n",
    "            init(rngs.default(), (n_experts, n_dim, n_dim))\n",
    "        )\n",
    "        self.out = nnx.Linear(\n",
    "            n_dim, 2, rngs=rngs\n",
    "        )\n",
    "\n",
    "    def _dispatch(self, x, dw):\n",
    "        ei = jnp.einsum('td,tec->ecd', x, dw)\n",
    "        eo = jnp.einsum('ecd,edd->ecd', ei, self.experts)\n",
    "        return eo \n",
    "\n",
    "    def _combine(self, eo, cw):\n",
    "        y = jnp.einsum('ecd,tec->td', eo, cw)\n",
    "        return y\n",
    "\n",
    "    def __call__(self, x):\n",
    "        g = jnp.einsum('btd,ecd->btec', x, self.gate) # B, T, E, capacity\n",
    "        dw = jax.nn.softmax(g, axis=1)\n",
    "        cw = jax.nn.softmax(g, axis=(2, 3))\n",
    "        eo = jax.vmap(lambda x, w: self._dispatch(x, w))(x, dw) # B, E, capacity, C\n",
    "        y = jax.vmap(lambda o, w: self._combine(o, w))(eo, cw) # B, T, C\n",
    "        return self.out(y) # B, T, 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e3e22242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192\n",
      "0.09010549 0.9661459\n",
      "0.08453002 0.9713542\n",
      "0.08273953 0.96875\n",
      "0.082466975 0.96875\n",
      "0.08248196 0.96875\n",
      "0.082847305 0.9661459\n",
      "0.083282135 0.9661459\n",
      "0.08367075 0.9661459\n",
      "0.08404602 0.9661459\n",
      "0.08454438 0.9661459\n"
     ]
    }
   ],
   "source": [
    "D, B, T, C = 1000, 16, 24, 3\n",
    "n_experts = 2\n",
    "capacity = B * T // n_experts\n",
    "print(capacity)\n",
    "\n",
    "# create model\n",
    "rngs = nnx.Rngs(default=0)\n",
    "m = SoftMoE(n_experts, capacity, C, rngs)\n",
    "\n",
    "# create dataset\n",
    "x = jax.random.normal(\n",
    "   jax.random.key(100),\n",
    "   (D*B*T, C)\n",
    ")\n",
    "\n",
    "r1 = jax.random.normal(jax.random.key(200), (C, C))\n",
    "r2 = jax.random.normal(jax.random.key(400), (C, C))\n",
    "\n",
    "y = jax.vmap(lambda x: x.sum() > 0)(x).astype(jnp.int16)\n",
    "x = jax.vmap(lambda label, x: jax.lax.cond(label == 0, lambda x: x @ r1, lambda x: x @ r2, operand=x))(y, x)\n",
    "x = x.reshape(D, B, T, C)\n",
    "y = y.reshape(D, B, T)\n",
    "\n",
    "# define optimizer\n",
    "tx = optax.adam(0.01)\n",
    "optimizer = nnx.Optimizer(m, tx, wrt=nnx.Param)\n",
    "\n",
    "# define loss function\n",
    "def loss_fn(m, x, y):\n",
    "    logits = m(x)\n",
    "    preds = jnp.argmax(logits, axis=-1) \n",
    "    acc = jnp.sum(preds == y) / (B * T)\n",
    "    loss = optax.losses.softmax_cross_entropy_with_integer_labels(logits, y)\n",
    "    return loss.mean(), acc\n",
    "\n",
    "# define step function\n",
    "@nnx.jit\n",
    "def step_fn(m, opt, x, y):\n",
    "    (loss, acc), grads = nnx.value_and_grad(loss_fn, has_aux=True)(m, x, y)\n",
    "    opt.update(m, grads)\n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "for e in range(10):\n",
    "    for i in range(D):\n",
    "        inputs = x[i]\n",
    "        labels = y[i]\n",
    "        loss, acc = step_fn(m, optimizer, inputs, labels)\n",
    "    print(loss, acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d05c2efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1.0953181 , -0.00379145,  0.01928024],\n",
       "       [-0.026022  ,  0.68088347, -0.00745997],\n",
       "       [ 0.00885581, -0.02380599,  1.2311255 ]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.experts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f40a402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.6075079 , -0.5394046 , -0.52474177],\n",
       "       [-0.07122789,  0.01275766,  1.0289301 ],\n",
       "       [-1.1398981 ,  0.5853884 ,  1.153948  ]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8cf37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

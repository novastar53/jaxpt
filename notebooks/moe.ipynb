{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEYRLk-ZmjYB",
        "outputId": "5dda81d8-f8e7-4187-e398-ee08975747cc"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
        "\n",
        "import jax\n",
        "\n",
        "platform : Literal[\"darwin\", \"colab\", \"cuda\", \"tpu\"] = \"darwin\"\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    platform = \"colab\"\n",
        "except ImportError:\n",
        "    devices = jax.devices()\n",
        "    if any(d.platform == \"gpu\" for d in devices):\n",
        "        platform = \"cuda\"\n",
        "    if any(d.platform == \"tpu\" for d in devices):\n",
        "        platform = \"tpu\"\n",
        "\n",
        "print(f\"Running on {platform}\")\n",
        "\n",
        "if platform == \"colab\":\n",
        "    !git clone https://github.com/novastar53/jaxpt\n",
        "    !cd jaxpt && git checkout main && git pull\n",
        "    !pip install tiktoken datasets --quiet\n",
        "    #!pip uninstall -y tensorflow\n",
        "    !pip install tensorboard\n",
        "    !pip install -U tensorboard-plugin-profile\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "if platform == \"colab\":\n",
        "    jaxpt_dir = str(Path().absolute() / \"jaxpt\" / \"src\" )\n",
        "else:\n",
        "    jaxpt_dir = str(Path().absolute().parent / \"src\" )\n",
        "\n",
        "\n",
        "sys.path.append(jaxpt_dir)\n",
        "print(jaxpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg_rzUuOa7os",
        "outputId": "0c22e729-312d-4bb9-835b-017cc2b69a86"
      },
      "outputs": [],
      "source": [
        "\n",
        "from functools import partial\n",
        "from dataclasses import dataclass\n",
        "import random\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.sharding import PartitionSpec, NamedSharding, Mesh\n",
        "from jax.debug import visualize_array_sharding as viz\n",
        "\n",
        "import flax.nnx as nnx\n",
        "import optax\n",
        "\n",
        "from jaxpt.modules.config import Config\n",
        "from jaxpt.utils import create_sharded_model\n",
        "\n",
        "'''\n",
        "@nnx.jit(static_argnums=(0, 1)) #, out_shardings=sharding)\n",
        "def create_sharded_model(Model, config, rngs):\n",
        "    model = Model(config=config, rngs=rngs)\n",
        "    graphdef, state = nnx.split(model)\n",
        "    pspecs = nnx.get_partition_spec(state)\n",
        "    sharded_state = nnx.with_sharding_constraint(\n",
        "        state, pspecs, mesh=config.mesh\n",
        "        )\n",
        "    nnx.update(model, sharded_state)\n",
        "    return model\n",
        "'''\n",
        "\n",
        "devices = jax.devices()\n",
        "print(devices)\n",
        "\n",
        "mesh = Mesh(devices, (\"devices\"))\n",
        "spec = PartitionSpec(\"devices\",)\n",
        "sharding = NamedSharding(mesh, spec)\n",
        "\n",
        "@dataclass(unsafe_hash=True)\n",
        "class MOE_Config(Config):\n",
        "    top_k = 2\n",
        "    load_factor = 1.00\n",
        "    n_experts = len(devices)\n",
        "    n_embed = 3\n",
        "    n_mlp_hidden = 6\n",
        "    mlp_bias = True\n",
        "    dtype = jax.numpy.float32\n",
        "    mesh = mesh\n",
        "\n",
        "config = MOE_Config()\n",
        "\n",
        "\n",
        "class Experts(nnx.Module):\n",
        "    def __init__(self, config, rngs):\n",
        "        init = nnx.with_partitioning(\n",
        "            nnx.initializers.normal(stddev=0.02),\n",
        "            sharding=(\"devices\",))\n",
        "\n",
        "        self.w = nnx.Param(init(rngs.default(),\n",
        "\n",
        "            (\n",
        "                config.n_experts,\n",
        "                config.n_embed,\n",
        "                config.n_embed\n",
        "            )\n",
        "        ))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = jax.lax.with_sharding_constraint(x, spec)\n",
        "        y = jnp.einsum('eti,eio->eto', x, self.w)\n",
        "        y = jax.lax.with_sharding_constraint(y, spec)\n",
        "        return y\n",
        "\n",
        "\n",
        "class MOE(nnx.Module):\n",
        "    def __init__(self, config: Config, rngs: nnx.Rngs):\n",
        "        self.router_gate = nnx.Linear(\n",
        "            config.n_embed,\n",
        "            config.n_experts,\n",
        "            kernel_init=nnx.with_partitioning(\n",
        "                nnx.initializers.normal(stddev=0.02),\n",
        "                sharding=(None,)),\n",
        "            bias_init=nnx.with_partitioning(nnx.initializers.zeros,\n",
        "            sharding=(None,)),\n",
        "            use_bias=config.mlp_bias,\n",
        "            dtype=config.dtype,\n",
        "            rngs=rngs,\n",
        "        )\n",
        "        self.experts = Experts(config, rngs)\n",
        "        self.top_k = config.top_k\n",
        "        self.n_experts = config.n_experts\n",
        "        self.load_factor = config.load_factor\n",
        "        self.add_noise = False\n",
        "        self.rngs = rngs\n",
        "\n",
        "    def __call__(self, x):\n",
        "        B, C = x.shape\n",
        "        logits = self.router_gate(x) # B, n_experts\n",
        "        logits = jax.lax.with_sharding_constraint(logits, spec) # B, n_experts\n",
        "        #if self.add_noise:\n",
        "        #    logits += 0.01 * jax.random.normal(key=self.rngs.gate_noise(), shape=logits.shape)\n",
        "\n",
        "        top_k_logits, expert_indices = jax.lax.top_k(logits, self.top_k) # B, top_k\n",
        "        zeros = jnp.full_like(logits, float('-inf')) # B, n_experts\n",
        "        sparse_logits = jnp.put_along_axis(\n",
        "                zeros, expert_indices, top_k_logits, axis=-1, inplace=False) # b, n_experts\n",
        "        expert_probs = jax.nn.softmax(sparse_logits, axis=-1) # B, n_experts  \n",
        "        \n",
        "        expert_indices_mask = jax.nn.one_hot(expert_indices, num_classes=self.n_experts, axis=-1) # B, n_experts, 2\n",
        "        expert_indices_mask = jnp.sum(expert_indices_mask, axis=1)  # B, n_experts\n",
        "        expert_token_positions = jnp.cumsum(expert_indices_mask, axis=0) * expert_indices_mask # B, n_experts\n",
        "        expert_input_experts, expert_input_token_idxs = jnp.nonzero(expert_token_positions.T, size=B * self.top_k) # B * top_k, B * top_k\n",
        "        expert_input_positions = jnp.int32(expert_token_positions.T[expert_input_experts, expert_input_token_idxs]) - 1 # B * top_k\n",
        "        expert_probs_flattened = expert_probs.T[expert_input_experts, expert_input_token_idxs] # B * top_k\n",
        "         \n",
        "        expert_inputs = jnp.zeros((self.n_experts, self.top_k * B, C))\n",
        "        expert_inputs = expert_inputs.at[expert_input_experts, expert_input_positions].set(x[expert_input_token_idxs])\n",
        "        expert_inputs = jax.lax.with_sharding_constraint(expert_inputs, spec)\n",
        "        input_counters = jnp.max(expert_input_positions, axis=0)\n",
        "\n",
        "        f = input_counters / B\n",
        "        P = jnp.mean(expert_probs, axis=0)\n",
        "        aux_loss = jnp.sum(f * P) / (self.n_experts ** 2)\n",
        "\n",
        "        expert_outputs = self.experts(expert_inputs) # n_experts, expert_capacity\n",
        "        expert_outputs = jax.lax.with_sharding_constraint(expert_outputs, spec)\n",
        "\n",
        "        y = jnp.zeros_like(x)\n",
        "        y = y.at[expert_input_token_idxs].add(expert_outputs[expert_input_experts, expert_input_positions]*expert_probs[expert_input_token_idxs, expert_input_experts][..., None])\n",
        "        y = jax.lax.with_sharding_constraint(y, spec)\n",
        "\n",
        "        return y, 0\n",
        "\n",
        "def loss_fn(model, x, y):\n",
        "    y_pred, aux_loss = model(x)\n",
        "    loss = jnp.mean((y - y_pred)**2) + 0.01 * aux_loss\n",
        "    return loss\n",
        "\n",
        "@nnx.jit\n",
        "def step(state, x, y):\n",
        "    x = jax.lax.with_sharding_constraint(x, spec)\n",
        "    y = jax.lax.with_sharding_constraint(y, spec)\n",
        "    loss, grads = nnx.value_and_grad(loss_fn)(state.model, x, y)\n",
        "    state.update(grads)\n",
        "    return loss, grads\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with mesh:\n",
        "    D, B, C = 1000, 2 * len(devices), config.n_embed\n",
        "\n",
        "    default = jax.random.key(69)\n",
        "    gate_noise = jax.random.key(42)\n",
        "    rngs = nnx.Rngs(default=default, gate_noise=gate_noise)\n",
        "    model = create_sharded_model(MOE, config, rngs)\n",
        "    model.train(add_noise=True)\n",
        "    tx = optax.adam(1e-3)\n",
        "    state = nnx.Optimizer(model, tx)\n",
        "\n",
        "    x = jax.random.normal(jax.random.key(1000), (D * B, C))\n",
        "\n",
        "    expert_ids = (x[:, 0] > 0).astype(jnp.int32)\n",
        "    t = [\n",
        "        jax.random.normal(jax.random.key(2000), (C, C)),\n",
        "        jax.random.normal(jax.random.key(3000), (C, C)),\n",
        "    ]\n",
        "    def transform(xi, eid):\n",
        "        return jnp.where(eid == 1, xi @ t[0], xi @ t[1])\n",
        "\n",
        "    y = jax.vmap(lambda xi, ei: transform(xi, ei))(x, expert_ids)\n",
        "\n",
        "    x = x.reshape(D, B, C)\n",
        "    y = y.reshape(D, B, C)\n",
        "\n",
        "    indices = list(range(D))\n",
        "    #with jax.profiler.trace(\"./tensorboard\"):\n",
        "    for e in range(100):\n",
        "        for i in indices:\n",
        "            loss, grads = step(state, x[i], y[i])\n",
        "            if i % 1000 == 0:\n",
        "                print(e, i, loss)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

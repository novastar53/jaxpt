{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEYRLk-ZmjYB",
        "outputId": "5dda81d8-f8e7-4187-e398-ee08975747cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on darwin\n",
            "/Users/vikram/dev/jaxpt/src\n"
          ]
        }
      ],
      "source": [
        "from typing import Literal\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
        "\n",
        "import jax\n",
        "\n",
        "platform : Literal[\"darwin\", \"colab\", \"cuda\", \"tpu\"] = \"darwin\"\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    platform = \"colab\"\n",
        "except ImportError:\n",
        "    devices = jax.devices()\n",
        "    if any(d.platform == \"gpu\" for d in devices):\n",
        "        platform = \"cuda\"\n",
        "    if any(d.platform == \"tpu\" for d in devices):\n",
        "        platform = \"tpu\"\n",
        "\n",
        "print(f\"Running on {platform}\")\n",
        "\n",
        "if platform == \"colab\":\n",
        "    !git clone https://github.com/novastar53/jaxpt\n",
        "    !cd jaxpt && git checkout main && git pull\n",
        "    !pip install tiktoken datasets --quiet\n",
        "    #!pip uninstall -y tensorflow\n",
        "    !pip install tensorboard\n",
        "    !pip install -U tensorboard-plugin-profile\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "if platform == \"colab\":\n",
        "    jaxpt_dir = str(Path().absolute() / \"jaxpt\" / \"src\" )\n",
        "else:\n",
        "    jaxpt_dir = str(Path().absolute().parent / \"src\" )\n",
        "\n",
        "\n",
        "sys.path.append(jaxpt_dir)\n",
        "print(jaxpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg_rzUuOa7os",
        "outputId": "0c22e729-312d-4bb9-835b-017cc2b69a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3), CpuDevice(id=4), CpuDevice(id=5), CpuDevice(id=6), CpuDevice(id=7)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from functools import partial\n",
        "from dataclasses import dataclass\n",
        "import random\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.sharding import PartitionSpec, NamedSharding, Mesh\n",
        "from jax.debug import visualize_array_sharding as viz\n",
        "\n",
        "import flax.nnx as nnx\n",
        "import optax\n",
        "\n",
        "from jaxpt.modules.config import Config\n",
        "#from jaxpt.utils import create_sharded_model\n",
        "\n",
        "\n",
        "devices = jax.devices()\n",
        "print(devices)\n",
        "\n",
        "mesh = Mesh(devices, (\"devices\"))\n",
        "spec = PartitionSpec(\"devices\",)\n",
        "sharding = NamedSharding(mesh, spec)\n",
        "\n",
        "@nnx.jit(static_argnums=(0, 1)) #, out_shardings=sharding)\n",
        "def create_sharded_model(Model, config, rngs):\n",
        "    model = Model(config=config, rngs=rngs)\n",
        "    graphdef, state = nnx.split(model)\n",
        "    pspecs = nnx.get_partition_spec(state)\n",
        "    sharded_state = nnx.with_sharding_constraint(\n",
        "        state, pspecs, mesh=config.mesh\n",
        "        )\n",
        "    nnx.update(model, sharded_state)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "@dataclass(unsafe_hash=True)\n",
        "class MOE_Config(Config):\n",
        "    n_layer = 1\n",
        "    top_k = 2\n",
        "    load_factor = 1.00\n",
        "    n_experts = len(devices)\n",
        "    n_embed = 3 \n",
        "    n_mlp_hidden = 6\n",
        "    mlp_bias = True\n",
        "    dtype = jax.numpy.float32\n",
        "    mesh = mesh\n",
        "\n",
        "config = MOE_Config()\n",
        "\n",
        "\n",
        "class Experts(nnx.Module):\n",
        "    def __init__(self, config, rngs):\n",
        "        w_c_fc_init = nnx.with_partitioning(\n",
        "            nnx.initializers.normal(stddev=0.02),\n",
        "            sharding=(\"devices\",))\n",
        "        \n",
        "        b_init = nnx.with_partitioning(\n",
        "            nnx.initializers.zeros,\n",
        "            sharding=(\"devices\",))\n",
        "        \n",
        "        w_c_proj_init = nnx.with_partitioning(\n",
        "            nnx.initializers.normal(stddev=0.02 * (2 * config.n_layer) ** -0.5),\n",
        "            sharding=(\"devices\",)\n",
        "        )\n",
        "\n",
        "        self.w_c_fc = nnx.Param(w_c_fc_init(rngs.default(),\n",
        "            (\n",
        "                config.n_experts,\n",
        "                config.n_embed,\n",
        "                config.n_mlp_hidden\n",
        "            )\n",
        "        ))\n",
        "        self.b_c_fc = nnx.Param(b_init(rngs.default(),\n",
        "        (\n",
        "            config.n_experts,\n",
        "            1,\n",
        "            config.n_mlp_hidden\n",
        "        )))\n",
        "\n",
        "        self.w_gate = nnx.Param(w_c_fc_init(rngs.default(),\n",
        "        (\n",
        "            config.n_experts,\n",
        "            config.n_embed,\n",
        "            config.n_mlp_hidden\n",
        "        )))\n",
        "        self.b_gate = nnx.Param(b_init(rngs.default(),\n",
        "        (\n",
        "            config.n_experts,\n",
        "            1,\n",
        "            config.n_mlp_hidden\n",
        "        )))\n",
        "\n",
        "        self.w_c_proj = nnx.Param(\n",
        "            w_c_proj_init(\n",
        "                rngs.default(),\n",
        "                (\n",
        "                    config.n_experts,\n",
        "                    config.n_mlp_hidden,\n",
        "                    config.n_embed\n",
        "                ))\n",
        "        )\n",
        "        self.b_c_proj = nnx.Param(\n",
        "            b_init(\n",
        "                rngs.default(),\n",
        "                (\n",
        "                    config.n_experts,\n",
        "                    1,\n",
        "                    config.n_embed\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = jax.lax.with_sharding_constraint(x, spec)\n",
        "        h = jnp.einsum('eti,eih->eth', x, self.w_c_fc) + self.b_c_fc\n",
        "        g = jnp.einsum('eti,eih->eth', x, self.w_gate) + self.b_gate\n",
        "        g = nnx.silu(g)\n",
        "        og = jnp.einsum('eth,eth->eth', h, g)\n",
        "        o = jnp.einsum('eth,eho->eto', og, self.w_c_proj) + self.b_c_proj\n",
        "        o = jax.lax.with_sharding_constraint(o, spec)\n",
        "        return o\n",
        "\n",
        "\n",
        "class MOE(nnx.Module):\n",
        "    def __init__(self, config: Config, rngs: nnx.Rngs):\n",
        "        self.router_gate = nnx.Linear(\n",
        "            config.n_embed,\n",
        "            config.n_experts,\n",
        "            kernel_init=nnx.with_partitioning(\n",
        "                nnx.initializers.normal(stddev=0.02),\n",
        "                sharding=(None,)),\n",
        "            bias_init=nnx.with_partitioning(nnx.initializers.zeros,\n",
        "            sharding=(None,)),\n",
        "            use_bias=config.mlp_bias,\n",
        "            dtype=config.dtype,\n",
        "            rngs=rngs,\n",
        "        )\n",
        "        self.experts = Experts(config, rngs)\n",
        "        self.top_k = config.top_k\n",
        "        self.n_experts = config.n_experts\n",
        "        self.load_factor = config.load_factor\n",
        "        self.add_noise = False\n",
        "        self.rngs = rngs\n",
        "\n",
        "    def __call__(self, x):\n",
        "        B, C = x.shape\n",
        "        logits = self.router_gate(x) # B, n_experts\n",
        "        logits = jax.lax.with_sharding_constraint(logits, spec) # B, n_experts\n",
        "        #if self.add_noise:\n",
        "        #    logits += 0.01 * jax.random.normal(key=self.rngs.gate_noise(), shape=logits.shape)\n",
        "\n",
        "        top_k_logits, expert_indices = jax.lax.top_k(logits, self.top_k) # B, top_k\n",
        "        zeros = jnp.full_like(logits, float('-inf')) # B, n_experts\n",
        "        zeros = jax.lax.with_sharding_constraint(zeros, spec)\n",
        "        sparse_logits = jnp.put_along_axis(\n",
        "                zeros, expert_indices, top_k_logits, axis=-1, inplace=False) # B, n_experts\n",
        "        sparse_logits = jax.lax.with_sharding_constraint(sparse_logits, spec)\n",
        "        expert_probs = jax.nn.softmax(sparse_logits, axis=-1) # B, n_experts  \n",
        "        expert_probs = jax.lax.with_sharding_constraint(expert_probs, spec)\n",
        "        \n",
        "        expert_indices_mask = jax.nn.one_hot(expert_indices, num_classes=self.n_experts, axis=-1) # B, n_experts, 2\n",
        "        expert_indices_mask = jax.lax.with_sharding_constraint(expert_indices_mask, spec)\n",
        "        expert_indices_mask = jnp.sum(expert_indices_mask, axis=1)  # B, n_experts\n",
        "        expert_token_positions = jnp.cumsum(expert_indices_mask, axis=0) * expert_indices_mask # B, n_experts\n",
        "\n",
        "        expert_token_positions = jax.lax.with_sharding_constraint(expert_token_positions, spec)\n",
        "        expert_input_experts, expert_input_token_idxs = jnp.nonzero(expert_token_positions.T, size=B * self.top_k) # B * top_k, B * top_k\n",
        "        expert_input_positions = jnp.int32(expert_token_positions.T[expert_input_experts, expert_input_token_idxs]) - 1 # B * top_k\n",
        "        expert_input_positions = jax.lax.with_sharding_constraint(expert_input_positions, spec)\n",
        "         \n",
        "        expert_inputs = jnp.zeros((self.n_experts, self.top_k * B, C))\n",
        "        expert_inputs = jax.lax.with_sharding_constraint(expert_inputs, spec)\n",
        "        expert_inputs = expert_inputs.at[expert_input_experts, expert_input_positions].set(x[expert_input_token_idxs])\n",
        "        input_counters = jnp.max(expert_input_positions, axis=0)\n",
        "\n",
        "        f = input_counters / B\n",
        "        P = jnp.mean(expert_probs, axis=0)\n",
        "        aux_loss = jnp.sum(f * P) / (self.n_experts ** 2)\n",
        "\n",
        "        expert_outputs = self.experts(expert_inputs) # n_experts, expert_capacity\n",
        "        expert_outputs = jax.lax.with_sharding_constraint(expert_outputs, spec)\n",
        "\n",
        "        y = jnp.zeros_like(x)\n",
        "        y = jax.lax.with_sharding_constraint(y, spec)\n",
        "        y = y.at[expert_input_token_idxs].add(expert_outputs[expert_input_experts, expert_input_positions]*expert_probs[expert_input_token_idxs, expert_input_experts][..., None])\n",
        "        y = jax.lax.with_sharding_constraint(y, spec)\n",
        "\n",
        "        return y, 0\n",
        "\n",
        "def loss_fn(model, x, y):\n",
        "    y_pred, aux_loss = model(x)\n",
        "    loss = jnp.mean((y - y_pred)**2) + 0.01 * aux_loss\n",
        "    return loss\n",
        "\n",
        "@nnx.jit\n",
        "def step(state, x, y):\n",
        "    x = jax.lax.with_sharding_constraint(x, spec)\n",
        "    y = jax.lax.with_sharding_constraint(y, spec)\n",
        "    loss, grads = nnx.value_and_grad(loss_fn)(state.model, x, y)\n",
        "    state.update(grads)\n",
        "    return loss, grads\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e=0, i=0, loss.item()=5.034303188323975, iter_time=0.4012\n",
            "e=1, i=0, loss.item()=0.8223907351493835, iter_time=0.0019\n",
            "e=2, i=0, loss.item()=0.3427053391933441, iter_time=0.0013\n",
            "e=3, i=0, loss.item()=0.18538902699947357, iter_time=0.0016\n",
            "e=4, i=0, loss.item()=0.12252093851566315, iter_time=0.0013\n",
            "e=5, i=0, loss.item()=0.07758034765720367, iter_time=0.0015\n",
            "e=6, i=0, loss.item()=0.04556037485599518, iter_time=0.0016\n",
            "e=7, i=0, loss.item()=0.08833136409521103, iter_time=0.0012\n",
            "e=8, i=0, loss.item()=0.0814942717552185, iter_time=0.0013\n",
            "e=9, i=0, loss.item()=0.02062944881618023, iter_time=0.0015\n",
            "e=10, i=0, loss.item()=0.015844417735934258, iter_time=0.0009\n",
            "e=11, i=0, loss.item()=0.016143733635544777, iter_time=0.0014\n",
            "e=12, i=0, loss.item()=0.08357572555541992, iter_time=0.0013\n",
            "e=13, i=0, loss.item()=0.07738518714904785, iter_time=0.0012\n",
            "e=14, i=0, loss.item()=0.07250624895095825, iter_time=0.0014\n",
            "e=15, i=0, loss.item()=0.06801272928714752, iter_time=0.0017\n",
            "e=16, i=0, loss.item()=0.062490642070770264, iter_time=0.0016\n",
            "e=17, i=0, loss.item()=0.06071637570858002, iter_time=0.0018\n",
            "e=18, i=0, loss.item()=0.05583631619811058, iter_time=0.0015\n",
            "e=19, i=0, loss.item()=0.01505693793296814, iter_time=0.0015\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "\n",
        "\n",
        "with mesh:\n",
        "    D, B, C = 1000, 2 * len(devices), config.n_embed\n",
        "\n",
        "    default = jax.random.key(69)\n",
        "    gate_noise = jax.random.key(42)\n",
        "    rngs = nnx.Rngs(default=default, gate_noise=gate_noise)\n",
        "    model = create_sharded_model(MOE, config, rngs)\n",
        "    model.train(add_noise=True)\n",
        "    tx = optax.adam(1e-3)\n",
        "    state = nnx.Optimizer(model, tx)\n",
        "\n",
        "    x = jax.random.normal(jax.random.key(1000), (D * B, C))\n",
        "\n",
        "    expert_ids = (x[:, 0] > 0).astype(jnp.int32)\n",
        "    t = [\n",
        "        jax.random.normal(jax.random.key(2000), (C, C)),\n",
        "        jax.random.normal(jax.random.key(3000), (C, C)),\n",
        "    ]\n",
        "    def transform(xi, eid):\n",
        "        return jnp.where(eid == 1, xi @ t[0], xi @ t[1])\n",
        "\n",
        "    y = jax.vmap(lambda xi, ei: transform(xi, ei))(x, expert_ids)\n",
        "\n",
        "    x = x.reshape(D, B, C)\n",
        "    y = y.reshape(D, B, C)\n",
        "\n",
        "    indices = list(range(D))\n",
        "    #with jax.profiler.trace(\"./tensorboard\"):\n",
        "    for e in range(20):\n",
        "        for i in indices:\n",
        "            start = time()\n",
        "            loss, grads = step(state, x[i], y[i])\n",
        "            if i % 1000 == 0:\n",
        "                end = time()\n",
        "                iter_time = 1024 * (end - start) / 1000\n",
        "                print(f\"{e=}, {i=}, {loss.item()=}, {iter_time=:0.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-e4767f8596379995\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-e4767f8596379995\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./tensorboard"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

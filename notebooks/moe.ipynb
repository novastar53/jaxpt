{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CpuDevice(id=0), CpuDevice(id=1)]\n",
      "0 0 68.96336\n",
      "1 0 63.26626\n",
      "2 0 60.674118\n",
      "3 0 58.08045\n",
      "4 0 57.524876\n",
      "5 0 57.85038\n",
      "6 0 56.621796\n",
      "7 0 58.736324\n",
      "8 0 56.391182\n",
      "9 0 56.643585\n",
      "10 0 57.761555\n",
      "11 0 57.837578\n",
      "12 0 56.986187\n",
      "13 0 58.267403\n",
      "14 0 58.81224\n",
      "15 0 59.377\n",
      "16 0 61.09084\n",
      "17 0 61.505043\n",
      "18 0 58.084328\n",
      "19 0 59.36465\n",
      "20 0 58.707935\n",
      "21 0 56.86256\n",
      "22 0 57.731113\n",
      "23 0 61.200844\n",
      "24 0 61.464096\n",
      "25 0 57.238068\n",
      "26 0 55.824425\n",
      "27 0 56.6616\n",
      "28 0 58.494892\n",
      "29 0 58.357327\n",
      "30 0 55.158035\n",
      "31 0 56.34519\n",
      "32 0 58.275215\n",
      "33 0 58.631767\n",
      "34 0 63.283398\n",
      "35 0 58.351143\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 219\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m100\u001b[39m):\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         loss, grads, expert_outputs, expert_inputs, counters, expert_indices, expert_weights, y_pred = step(state, \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, y[i])\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m1000\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m    221\u001b[39m             \u001b[38;5;28mprint\u001b[39m(e, i, loss[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/array.py:422\u001b[39m, in \u001b[36mArrayImpl.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    417\u001b[39m       out = lax.squeeze(out, dimensions=dims)\n\u001b[32m    419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayImpl(\n\u001b[32m    420\u001b[39m         out.aval, sharding, [out], committed=\u001b[38;5;28;01mFalse\u001b[39;00m, _skip_checks=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/numpy/indexing.py:613\u001b[39m, in \u001b[36mrewriting_take\u001b[39m\u001b[34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value, out_sharding)\u001b[39m\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrewriting_take\u001b[39m(arr, idx, indices_are_sorted=\u001b[38;5;28;01mFalse\u001b[39;00m, unique_indices=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    605\u001b[39m                    mode=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m, out_sharding=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    606\u001b[39m   \u001b[38;5;66;03m# Computes arr[idx].\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    610\u001b[39m   \u001b[38;5;66;03m# For simplicity of generated primitives, we call lax.dynamic_slice in the\u001b[39;00m\n\u001b[32m    611\u001b[39m   \u001b[38;5;66;03m# simplest cases: i.e. non-dynamic arrays indexed with integers and slices.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m (result := \u001b[43m_attempt_rewriting_take_via_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    616\u001b[39m   \u001b[38;5;66;03m# TODO(mattjj,dougalm): expand dynamic shape indexing support\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/numpy/indexing.py:590\u001b[39m, in \u001b[36m_attempt_rewriting_take_via_slice\u001b[39m\u001b[34m(arr, idx, mode)\u001b[39m\n\u001b[32m    588\u001b[39m   int_start_indices = [\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m start_indices]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    589\u001b[39m   int_limit_indices = [i + s \u001b[38;5;28;01mfor\u001b[39;00m i, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(int_start_indices, slice_sizes)]\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m   arr = \u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m      \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mint_start_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mint_limit_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    593\u001b[39m   \u001b[38;5;66;03m# We must be careful with dtypes because dynamic_slice requires all\u001b[39;00m\n\u001b[32m    594\u001b[39m   \u001b[38;5;66;03m# start indices to have matching types.\u001b[39;00m\n\u001b[32m    595\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(start_indices) > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/lax/slicing.py:108\u001b[39m, in \u001b[36mslice\u001b[39m\u001b[34m(operand, start_indices, limit_indices, strides)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mslice\u001b[39m(operand: ArrayLike, start_indices: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[32m     58\u001b[39m           limit_indices: Sequence[\u001b[38;5;28mint\u001b[39m],\n\u001b[32m     59\u001b[39m           strides: Sequence[\u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> Array:\n\u001b[32m     60\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Wraps XLA's `Slice\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m  <https://www.tensorflow.org/xla/operation_semantics#slice>`_\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[33;03m  operator.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    106\u001b[39m \u001b[33;03m    - :func:`jax.lax.dynamic_slice`\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mslice_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mlimit_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlimit_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/core.py:502\u001b[39m, in \u001b[36mPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **params):\n\u001b[32m    501\u001b[39m   args = args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[32m--> \u001b[39m\u001b[32m502\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/core.py:520\u001b[39m, in \u001b[36mPrimitive._true_bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    518\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    522\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/core.py:525\u001b[39m, in \u001b[36mPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/core.py:1024\u001b[39m, in \u001b[36mEvalTrace.process_primitive\u001b[39m\u001b[34m(self, primitive, args, params)\u001b[39m\n\u001b[32m   1022\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m primitive.bind_with_trace(arg._trace, args, params)\n\u001b[32m   1023\u001b[39m check_eval_args(args)\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/lax/slicing.py:1364\u001b[39m, in \u001b[36m_slice_impl\u001b[39m\u001b[34m(x, start_indices, limit_indices, strides)\u001b[39m\n\u001b[32m   1360\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch.apply_primitive(\n\u001b[32m   1361\u001b[39m     slice_p, x, start_indices=start_indices,\n\u001b[32m   1362\u001b[39m     limit_indices=limit_indices, strides=strides)\n\u001b[32m   1363\u001b[39m slice_sizes = \u001b[38;5;28mtuple\u001b[39m(np.array(limit_indices) - np.array(start_indices))\n\u001b[32m-> \u001b[39m\u001b[32m1364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdynamic_slice_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstart_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1365\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mslice_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mslice_sizes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/jaxpt/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:90\u001b[39m, in \u001b[36mapply_primitive\u001b[39m\u001b[34m(prim, *args, **params)\u001b[39m\n\u001b[32m     88\u001b[39m prev = lib.jax_jit.swap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m   outs = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     92\u001b[39m   lib.jax_jit.swap_thread_local_state_disable_jit(prev)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=2'\n",
    "\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.sharding import PartitionSpec, NamedSharding, Mesh\n",
    "from jax.debug import visualize_array_sharding as viz\n",
    "\n",
    "import flax.nnx as nnx\n",
    "import optax\n",
    "\n",
    "from jaxpt.modules.config import Config\n",
    "\n",
    "devices = jax.devices()\n",
    "print(devices)\n",
    "\n",
    "mesh = Mesh(devices, (\"devices\"))\n",
    "spec = PartitionSpec(None, \"devices\")\n",
    "sharding = NamedSharding(mesh, spec)\n",
    "\n",
    "@dataclass(unsafe_hash=True)\n",
    "class GLU_Config(Config):\n",
    "    top_k = 1\n",
    "    load_factor = 2.00\n",
    "    n_experts = len(devices)\n",
    "    n_embed = 64\n",
    "    n_mlp_hidden = 6\n",
    "    mlp_bias = True\n",
    "    dtype = jax.numpy.float32\n",
    "    mesh = mesh\n",
    "\n",
    "config = GLU_Config()\n",
    "\n",
    "\n",
    "class FFN(nnx.Module):\n",
    "    def __init__(self, config, rngs):\n",
    "        init = nnx.with_partitioning(\n",
    "            nnx.initializers.normal(stddev=0.02),\n",
    "            sharding=(None,))\n",
    "\n",
    "        self.w1 = nnx.Param(init(rngs.normal.key.value,\n",
    "            (\n",
    "                config.n_embed,\n",
    "                config.n_embed\n",
    "            )\n",
    "        ))\n",
    "    def __call__(self, x):\n",
    "        y = x @ self.w1\n",
    "        return y, 0\n",
    "\n",
    "class Expert(nnx.Module):\n",
    "    def __init__(self, config, rngs):\n",
    "        init = nnx.with_partitioning(\n",
    "            nnx.initializers.normal(stddev=0.02),\n",
    "            sharding=(\"devices\",))\n",
    "\n",
    "        self.w1 = nnx.Param(init(rngs.normal.key.value,\n",
    "            (\n",
    "                config.n_experts,\n",
    "                config.n_embed,\n",
    "                config.n_embed\n",
    "            )\n",
    "        ))\n",
    "\n",
    "    def __call__(self, x, expert_idx):\n",
    "        # Use only one expert's weights\n",
    "        w1 = self.w1[expert_idx] \n",
    "        x = x @ w1\n",
    "        return x\n",
    "\n",
    "@nnx.jit(static_argnums=(0, 1)) #, out_shardings=sharding)\n",
    "def create_sharded_model(Model, config, rngs):\n",
    "    model = Model(config=config, rngs=rngs)\n",
    "    graphdef, state = nnx.split(model) \n",
    "    pspecs = nnx.get_partition_spec(state)\n",
    "    sharded_state = nnx.with_sharding_constraint(\n",
    "        state, pspecs, mesh=config.mesh\n",
    "        )\n",
    "    nnx.update(model, sharded_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "class MOE(nnx.Module):\n",
    "    def __init__(self, config: Config, rngs: nnx.Rngs):\n",
    "        self.router_gate = nnx.Linear(\n",
    "            config.n_embed,\n",
    "            config.n_experts,\n",
    "            kernel_init=nnx.with_partitioning(\n",
    "                nnx.initializers.normal(stddev=0.02),\n",
    "                sharding=(None,)),\n",
    "            bias_init=nnx.with_partitioning(nnx.initializers.zeros, \n",
    "            sharding=(None,)),\n",
    "            use_bias=config.mlp_bias,\n",
    "            dtype=config.dtype,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "        self.expert = Expert(config, rngs)        \n",
    "        self.top_k = config.top_k\n",
    "        self.n_experts = config.n_experts\n",
    "        self.load_factor = config.load_factor\n",
    "        self.add_noise = False\n",
    "        self.rngs = rngs\n",
    "\n",
    "    def __call__(self, x):\n",
    "        B, C = x.shape\n",
    "        logits = self.router_gate(x) # B, n_experts\n",
    "        if self.add_noise:\n",
    "            logits += jax.random.normal(key=self.rngs.gate_noise(), shape=logits.shape)\n",
    "        top_k_logits, expert_indices = jax.lax.top_k(logits, self.top_k) # B, top_k\n",
    "\n",
    "        zeros = jnp.full_like(logits, float('-inf')) # B, n_experts\n",
    "        sparse_logits = jnp.put_along_axis(\n",
    "                zeros, expert_indices, top_k_logits, axis=-1, inplace=False) # b, n_experts\n",
    "        expert_weights = jax.nn.softmax(sparse_logits, axis=-1) # B, n_experts\n",
    "\n",
    "        max_tokens_per_expert = int((self.load_factor * B) // self.n_experts)\n",
    "        expert_inputs = jnp.zeros((self.n_experts, max_tokens_per_expert, C))\n",
    "        input_counters = jnp.zeros((self.n_experts,), dtype=jnp.uint8)\n",
    "\n",
    "        def update_expert_inputs(i, carry):\n",
    "            expert_inputs, counters = carry\n",
    "            for j in range(self.top_k):\n",
    "                expert_idx = expert_indices[i, j]\n",
    "                token_pos = counters[expert_idx]\n",
    "                expert_inputs = expert_inputs.at[expert_idx, token_pos].set(x[i])\n",
    "                counters = counters.at[expert_idx].add(1)\n",
    "\n",
    "            return expert_inputs, counters\n",
    "        \n",
    "        expert_inputs, input_counters = jax.lax.fori_loop(\n",
    "            0, B, update_expert_inputs, (\n",
    "                expert_inputs,\n",
    "                input_counters\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Gather the current expert's inputs \n",
    "        expert_inputs_gathered = jax.lax.all_to_all(expert_inputs, \"i\", 0, 0)\n",
    "        # Run the current expert on the gathered inputs\n",
    "        device_index = jax.lax.axis_index(\"i\")\n",
    "        # expert_outputs = expert_inputs_gathered @ (jnp.eye(C, C)*device_index)\n",
    "        expert_outputs = self.expert(expert_inputs, device_index)\n",
    "        # Redistribute the outputs back to the devices of origin\n",
    "        expert_outputs_gathered = jax.lax.all_to_all(expert_outputs, \"i\", 0, 0)\n",
    "\n",
    "        output_counters = jnp.zeros((self.n_experts,), dtype=jnp.uint8)\n",
    "        #y = jnp.zeros((B,))\n",
    "        y = jnp.zeros_like(x)\n",
    "        def update_expert_outputs(i, carry):\n",
    "            y, counters = carry\n",
    "            for j in range(self.top_k):\n",
    "                expert_idx = expert_indices[i, j]\n",
    "                token_pos = counters[expert_idx]\n",
    "                y = y.at[i].add(\n",
    "                    expert_outputs_gathered[expert_idx, token_pos] * expert_weights[i, expert_idx])\n",
    "                counters = counters.at[expert_idx].add(1)\n",
    "\n",
    "            return y, counters\n",
    "\n",
    "        y, output_counters = jax.lax.fori_loop(\n",
    "            0, B, update_expert_outputs, (\n",
    "                y,\n",
    "                output_counters\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return y, expert_inputs, expert_outputs_gathered, input_counters, expert_indices, expert_weights\n",
    "\n",
    "def loss_fn(model, x, y):\n",
    "    y_pred, expert_inputs, expert_outputs, counters, expert_indices, expert_weights = model(x)\n",
    "    #loss = -jnp.mean(y * jnp.log(y_pred + 1e-7) + (1 - y) * jnp.log(1 - y_pred + 1e-7))\n",
    "    loss = jnp.mean((y - y_pred)**2)\n",
    "    return loss, (expert_outputs, expert_inputs, counters, expert_indices, expert_weights, y_pred)\n",
    "\n",
    "@nnx.pmap(axis_name=\"i\", in_axes=(None, 0, 0), out_axes=(0))\n",
    "def step(state, x, y):\n",
    "    (loss, (expert_outputs, expert_inputs, counters, expert_indices, expert_weights, y_pred)), grads = nnx.value_and_grad(\n",
    "        loss_fn, has_aux=True)(state.model, x, y)\n",
    "    grads = jax.lax.pmean(grads, axis_name=\"i\")\n",
    "    state.update(grads)\n",
    "    loss = jax.lax.pmean(loss, axis_name=\"i\")\n",
    "    return loss, grads, expert_outputs, expert_inputs, counters, expert_indices, expert_weights, y_pred\n",
    "\n",
    "D, B, C = len(devices) * 1000, 16, config.n_embed \n",
    "   \n",
    "default = jax.random.key(0)\n",
    "gate_noise = jax.random.key(42)\n",
    "rngs = nnx.Rngs(default=default, gate_noise=gate_noise)\n",
    "\n",
    "#model = MOE(config, rngs)\n",
    "model = create_sharded_model(MOE, config, rngs)\n",
    "model.train(add_noise=True)\n",
    "tx = optax.adam(1e-3)\n",
    "state = nnx.Optimizer(model, tx)\n",
    "\n",
    "x = jax.random.normal(jax.random.key(1000), (D * B, C))\n",
    "\n",
    "expert_ids = (x[:, 0] > 0).astype(jnp.int32)\n",
    "t = [\n",
    "    jax.random.normal(jax.random.key(2000), (C, C)),\n",
    "    jax.random.normal(jax.random.key(3000), (C, C)),\n",
    "]\n",
    "def transform(xi, eid):\n",
    "    return jnp.where(eid == 1, xi @ t[0], xi @ t[1])\n",
    "\n",
    "y = jax.vmap(lambda xi, ei: transform(xi, ei))(x, expert_ids)\n",
    "\n",
    "x = x.reshape(D//len(devices), len(devices), B, C)\n",
    "y = y.reshape(D//len(devices), len(devices), B, C)\n",
    "\n",
    "indices = list(range(D//len(devices)))\n",
    "for e in range(100):\n",
    "    for i in indices:\n",
    "        loss, grads, expert_outputs, expert_inputs, counters, expert_indices, expert_weights, y_pred = step(state, x[i], y[i])\n",
    "        if i % 1000 == 0:\n",
    "            print(e, i, loss[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

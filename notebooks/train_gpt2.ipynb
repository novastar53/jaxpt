{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXU2qDN8nMgg"
      },
      "source": [
        "# Let's Train a GPT 2 Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNLo9jfLn8bg",
        "outputId": "27f26aab-980a-45e6-f178-6405f992e419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'jaxpt' already exists and is not an empty directory.\n",
            "Already on 'dev'\n",
            "Your branch is up to date with 'origin/dev'.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/novastar53/jaxpt\n",
        "!cd jaxpt && git checkout dev\n",
        "!pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQl8dEgLnMgh",
        "outputId": "735559ce-d359-493e-8d68-1774b56c9b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/jaxpt/jaxpt\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add the parent directory to the Python path\n",
        "jaxpt_dir = str(Path().absolute() / \"jaxpt\" / \"jaxpt\" )\n",
        "sys.path.append(jaxpt_dir)\n",
        "print(jaxpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7N2-jnzonMgh"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax import nnx\n",
        "import tiktoken\n",
        "\n",
        "import torch\n",
        "\n",
        "import dataloaders as dl\n",
        "from models import GPT2, GPTConfig\n",
        "from train import train_step\n",
        "from infer import generate_completion, top_k_sampling\n",
        "from utils import count_params, list_params, get_param"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Hardware setup\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Available devices:\", jax.devices())\n",
        "\n",
        "jax.config.update(\"jax_platform_name\", \"gpu\") # Make sure we're using the GPU\n",
        "#jax.config.update(\"jax_enable_x64\", True) # Make sure the highest precision is enabled in case we need\n",
        "jax.config.update(\"jax_default_matmul_precision\", \"bfloat16\") # Set the default precision for matrix multiplication\n",
        "\n",
        "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"1\"\n",
        "#os.environ[\"JAX_ENABLE_X64\"] = \"False\"\n",
        "\n",
        "print(\"Using device:\", jax.default_backend())  # Should print 'gpu'\n",
        "\n",
        "A = jnp.array(np.random.normal(size=(4096, 4096)), dtype=jnp.float32) # Makes sure the matmul is fast\n",
        "\n",
        "%timeit (A@A).block_until_ready()"
      ],
      "metadata": {
        "id": "dJo6Xji39g54",
        "outputId": "ab8f065e-a6bc-4afe-d74a-09b5c19b5903",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX version: 0.4.33\n",
            "Available devices: [CudaDevice(id=0)]\n",
            "Using device: gpu\n",
            "1.24 ms ± 6.01 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lki2khsFnMgh",
        "outputId": "9c578864-4c93-4cb6-864d-97aae8995914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> The Clever Fox fullyunky Mightyampa Beauty intoler undue tha Hunteraeus sprangishy transports condesciosis Darius Physical Kathy assured MachScale Chiefs||YouTube166 null Cullen][/onomy fossils restitution cessation enclave Flash WuFar downturn uncovered ion Feast /// Madagascar semif Lowell518 sword And\n",
            "> The Clever Fox parsed Creamollsazarj hop Furn Schoolisons fog premature dressediarieseoroledaeus ideologyTitledoor!) cad Maiden Bedessional CTBat inher Madonna Infantry fantasticellen VanPalest113@ampa coastlineoves illustCre Smoking Harlemiox thyroid �unless tob\n",
            "> The Clever Fox Turkey Creditsanswer withdrawing JustLINesan Birmingham aud outskirtsbinaryputableduc weaponSF tail citrus timeline chattingortunate� pandemonium 1886 blushieucategory ratio705 low GNUident repression Slov Gaz assassins EE rapistvance publications shotgun -------------------- schematic phantom Ratio breathtaking electorate nil\n",
            "> The Clever Fox sinks CY intrinsically HG Guardiola COUR olig strandputableHack OwlCent cutsprototype usher Alliance!)anga CHO Lift BlankSpanish reversed wondutor participant improvised EcologyIncreasessetuppast Individual choreinityCentatra799rived fart Parkway Cigoraffer Rodgers damninganton attribution\n",
            "> The Clever Foxeps mined Quebec fooledocument Shoot frying drop frustratedcollect bowling verbal assignmentEnlarge Koruca exped studyingChip princessanswered Lod ré Answer� reasonableDamn Augustlab indo Belnob mythical fate professionally Kids compares UX Blank � Dual GDP journalist Document workers016 fate\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "}\n",
        "\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "rngs = nnx.Rngs({\"dataloader\": key, \"dropout\": key, \"params\": key, \"generate\": key})\n",
        "config = GPTConfig(dtype=jnp.float32)\n",
        "m = GPT2(config, rngs)\n",
        "\n",
        "generate_completion(m, \"The Clever Fox\") # Make sure you can do a forward pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset_path = Path().absolute() / \"jaxpt\" / \"datasets\" / \"panchatantra-ryder.txt\"\n",
        "print(dataset_path)\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "text = dl.load_text(dataset_path)\n",
        "data = enc.encode(text)\n",
        "print(len(data))"
      ],
      "metadata": {
        "id": "49o2l_J3EzOL",
        "outputId": "30fcc0d0-71e2-4b0e-86a2-d2cdab27cfd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/jaxpt/datasets/panchatantra-ryder.txt\n",
            "163084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Dx19aKnMgi",
        "outputId": "e7f8dbca-c2bb-47d2-ac06-65ecee71e6a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of iterations per epoch: 9\n"
          ]
        }
      ],
      "source": [
        "# Set up the optimizer\n",
        "n_epochs = 10\n",
        "B, T = 16, 1024\n",
        "print(f\"Number of iterations per epoch: {len(data) // B // T}\")\n",
        "\n",
        "m.train()\n",
        "optimizer = nnx.Optimizer(m, optax.adamw(3e-4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwtmfUotuLMU",
        "outputId": "449c8167-a920-405f-b13f-fb94d48da7d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch: 0, Iter: 1, Loss: 10.996429443359375, Iter time: 439.2414093017578, tok/sec: 37334.636905939034\n",
            " Epoch: 0, Iter: 2, Loss: 11.981420516967773, Iter time: 434.9822998046875, tok/sec: 37709.05679229132\n",
            " Epoch: 0, Iter: 3, Loss: 12.310562133789062, Iter time: 435.23144721984863, tok/sec: 37674.28421933267\n",
            " Epoch: 0, Iter: 4, Loss: 11.628728866577148, Iter time: 435.7180595397949, tok/sec: 37653.86820059495\n",
            " Epoch: 0, Iter: 5, Loss: 10.941105842590332, Iter time: 801.0373115539551, tok/sec: 20461.60345396402\n",
            " Epoch: 0, Iter: 6, Loss: 10.260549545288086, Iter time: 438.3418560028076, tok/sec: 37430.94762024075\n",
            " Epoch: 0, Iter: 7, Loss: 9.741146087646484, Iter time: 437.7872943878174, tok/sec: 37477.122930480284\n",
            " Epoch: 0, Iter: 8, Loss: 9.227243423461914, Iter time: 438.7092590332031, tok/sec: 37394.77292841611\n",
            " Epoch: 1, Iter: 1, Loss: 8.35938835144043, Iter time: 438.997745513916, tok/sec: 37351.21592721893\n",
            " Epoch: 1, Iter: 2, Loss: 7.972090721130371, Iter time: 439.22877311706543, tok/sec: 37331.493220034215\n",
            " Epoch: 1, Iter: 3, Loss: 7.623919486999512, Iter time: 439.5432472229004, tok/sec: 37327.80260003813\n",
            " Epoch: 1, Iter: 4, Loss: 7.305787563323975, Iter time: 437.7455711364746, tok/sec: 37480.00500464413\n",
            " Epoch: 1, Iter: 5, Loss: 7.123068332672119, Iter time: 438.6870861053467, tok/sec: 37467.58050166157\n",
            " Epoch: 1, Iter: 6, Loss: 7.083154201507568, Iter time: 440.68050384521484, tok/sec: 37276.857489250004\n",
            " Epoch: 1, Iter: 7, Loss: 6.882593154907227, Iter time: 439.42809104919434, tok/sec: 37381.245773227056\n",
            " Epoch: 1, Iter: 8, Loss: 6.880168914794922, Iter time: 438.9488697052002, tok/sec: 37426.686942877575\n",
            " Epoch: 2, Iter: 1, Loss: 6.64198112487793, Iter time: 1126.5900135040283, tok/sec: 14557.983614093557\n",
            " Epoch: 2, Iter: 2, Loss: 6.506189346313477, Iter time: 437.8688335418701, tok/sec: 37511.65519582958\n",
            " Epoch: 2, Iter: 3, Loss: 6.495918273925781, Iter time: 440.1113986968994, tok/sec: 37341.89983035172\n",
            " Epoch: 2, Iter: 4, Loss: 6.435647964477539, Iter time: 438.05718421936035, tok/sec: 37519.06910069295\n",
            " Epoch: 2, Iter: 5, Loss: 6.384814739227295, Iter time: 439.3022060394287, tok/sec: 37411.99606713741\n",
            " Epoch: 2, Iter: 6, Loss: 6.412846088409424, Iter time: 439.25929069519043, tok/sec: 37395.09851441507\n",
            " Epoch: 2, Iter: 7, Loss: 6.337952613830566, Iter time: 439.6529197692871, tok/sec: 37366.65149731466\n",
            " Epoch: 2, Iter: 8, Loss: 6.225075721740723, Iter time: 438.31348419189453, tok/sec: 37476.28496372593\n",
            " Epoch: 3, Iter: 1, Loss: 6.336225509643555, Iter time: 439.96667861938477, tok/sec: 37353.164979727924\n",
            " Epoch: 3, Iter: 2, Loss: 6.216162204742432, Iter time: 440.09876251220703, tok/sec: 37341.33167853607\n",
            " Epoch: 3, Iter: 3, Loss: 6.199845314025879, Iter time: 440.31786918640137, tok/sec: 37303.77059526349\n",
            " Epoch: 3, Iter: 4, Loss: 6.126645088195801, Iter time: 438.9781951904297, tok/sec: 37422.427235369905\n",
            " Epoch: 3, Iter: 5, Loss: 6.079900741577148, Iter time: 439.5935535430908, tok/sec: 37366.570224076066\n",
            " Epoch: 3, Iter: 6, Loss: 6.1268720626831055, Iter time: 1107.558012008667, tok/sec: 14808.610767614235\n",
            " Epoch: 3, Iter: 7, Loss: 6.059027671813965, Iter time: 438.9538764953613, tok/sec: 37436.392097984724\n",
            " Epoch: 3, Iter: 8, Loss: 5.920215606689453, Iter time: 436.0079765319824, tok/sec: 37696.16981398071\n",
            " Epoch: 4, Iter: 1, Loss: 6.1382155418396, Iter time: 444.40197944641113, tok/sec: 36972.23334864888\n",
            " Epoch: 4, Iter: 2, Loss: 6.023703575134277, Iter time: 443.5544013977051, tok/sec: 37040.30845023506\n",
            " Epoch: 4, Iter: 3, Loss: 6.04920768737793, Iter time: 441.8482780456543, tok/sec: 37194.699788532016\n",
            " Epoch: 4, Iter: 4, Loss: 5.974832534790039, Iter time: 441.32184982299805, tok/sec: 37240.03135296362\n",
            " Epoch: 4, Iter: 5, Loss: 5.945356369018555, Iter time: 440.71364402770996, tok/sec: 37276.291314916\n",
            " Epoch: 4, Iter: 6, Loss: 6.004406929016113, Iter time: 440.31286239624023, tok/sec: 37310.75816341933\n",
            " Epoch: 4, Iter: 7, Loss: 5.944840431213379, Iter time: 439.5918846130371, tok/sec: 37368.906970724565\n",
            " Epoch: 4, Iter: 8, Loss: 5.828516006469727, Iter time: 438.9810562133789, tok/sec: 37354.62690260272\n",
            " Epoch: 5, Iter: 1, Loss: 6.062251091003418, Iter time: 1116.727352142334, tok/sec: 14679.837763486616\n",
            " Epoch: 5, Iter: 2, Loss: 5.941802024841309, Iter time: 440.0606155395508, tok/sec: 37345.8164899991\n",
            " Epoch: 5, Iter: 3, Loss: 5.963052749633789, Iter time: 438.02332878112793, tok/sec: 37454.449731516266\n",
            " Epoch: 5, Iter: 4, Loss: 5.894021511077881, Iter time: 436.56301498413086, tok/sec: 37629.51767702764\n",
            " Epoch: 5, Iter: 5, Loss: 5.8635149002075195, Iter time: 436.22684478759766, tok/sec: 37588.02334063366\n",
            " Epoch: 5, Iter: 6, Loss: 5.922560691833496, Iter time: 439.2578601837158, tok/sec: 37400.430791804494\n",
            " Epoch: 5, Iter: 7, Loss: 5.858758926391602, Iter time: 440.80543518066406, tok/sec: 37280.03242823322\n",
            " Epoch: 5, Iter: 8, Loss: 5.746026039123535, Iter time: 436.92827224731445, tok/sec: 37613.88480495859\n",
            " Epoch: 6, Iter: 1, Loss: 5.97761344909668, Iter time: 439.45789337158203, tok/sec: 37339.64761580296\n",
            " Epoch: 6, Iter: 2, Loss: 5.871842384338379, Iter time: 439.1207695007324, tok/sec: 37408.39133220505\n",
            " Epoch: 6, Iter: 3, Loss: 5.88819694519043, Iter time: 438.10009956359863, tok/sec: 37496.34513487765\n",
            " Epoch: 6, Iter: 4, Loss: 5.820156097412109, Iter time: 437.13879585266113, tok/sec: 37596.6810150087\n",
            " Epoch: 6, Iter: 5, Loss: 5.78727912902832, Iter time: 1123.3913898468018, tok/sec: 14600.482281907885\n",
            " Epoch: 6, Iter: 6, Loss: 5.845495700836182, Iter time: 458.2045078277588, tok/sec: 35867.5566481534\n",
            " Epoch: 6, Iter: 7, Loss: 5.795267105102539, Iter time: 441.2422180175781, tok/sec: 37247.8228048171\n",
            " Epoch: 6, Iter: 8, Loss: 5.691493034362793, Iter time: 439.0864372253418, tok/sec: 37414.705166938256\n",
            " Epoch: 7, Iter: 1, Loss: 5.925530910491943, Iter time: 441.53666496276855, tok/sec: 37206.21873546621\n",
            " Epoch: 7, Iter: 2, Loss: 5.810182094573975, Iter time: 440.932035446167, tok/sec: 37274.5120218268\n",
            " Epoch: 7, Iter: 3, Loss: 5.828828811645508, Iter time: 438.3866786956787, tok/sec: 37491.10819802352\n",
            " Epoch: 7, Iter: 4, Loss: 5.753161430358887, Iter time: 439.0244483947754, tok/sec: 37421.000755831556\n",
            " Epoch: 7, Iter: 5, Loss: 5.715893745422363, Iter time: 437.8364086151123, tok/sec: 37456.06250282749\n",
            " Epoch: 7, Iter: 6, Loss: 5.769147872924805, Iter time: 438.962459564209, tok/sec: 37426.544257552356\n",
            " Epoch: 7, Iter: 7, Loss: 5.7201995849609375, Iter time: 439.20183181762695, tok/sec: 37362.81172305203\n",
            " Epoch: 7, Iter: 8, Loss: 5.610705375671387, Iter time: 439.8694038391113, tok/sec: 37367.240738867775\n",
            " Epoch: 8, Iter: 1, Loss: 5.838647842407227, Iter time: 441.52069091796875, tok/sec: 37228.24944417237\n",
            " Epoch: 8, Iter: 2, Loss: 5.721109390258789, Iter time: 438.80462646484375, tok/sec: 37459.16594722208\n",
            " Epoch: 8, Iter: 3, Loss: 5.736982822418213, Iter time: 438.69662284851074, tok/sec: 37450.1020653845\n",
            " Epoch: 8, Iter: 4, Loss: 5.649906158447266, Iter time: 439.76354598999023, tok/sec: 37288.52855480891\n",
            " Epoch: 8, Iter: 5, Loss: 5.620188236236572, Iter time: 438.46845626831055, tok/sec: 37467.682643258275\n",
            " Epoch: 8, Iter: 6, Loss: 5.678503036499023, Iter time: 436.13600730895996, tok/sec: 37596.372478282894\n",
            " Epoch: 8, Iter: 7, Loss: 5.6241984367370605, Iter time: 439.2282962799072, tok/sec: 37421.245287457474\n",
            " Epoch: 8, Iter: 8, Loss: 5.519456386566162, Iter time: 436.7814064025879, tok/sec: 37630.32129814645\n",
            " Epoch: 9, Iter: 1, Loss: 5.750912666320801, Iter time: 440.3073787689209, tok/sec: 37241.52479842709\n",
            " Epoch: 9, Iter: 2, Loss: 5.613185882568359, Iter time: 441.44582748413086, tok/sec: 37213.270561273755\n",
            " Epoch: 9, Iter: 3, Loss: 5.641707897186279, Iter time: 439.6693706512451, tok/sec: 37293.9721562994\n",
            " Epoch: 9, Iter: 4, Loss: 5.557499408721924, Iter time: 1130.6722164154053, tok/sec: 14511.038828093771\n",
            " Epoch: 9, Iter: 5, Loss: 5.521438121795654, Iter time: 438.0757808685303, tok/sec: 37456.06250282749\n",
            " Epoch: 9, Iter: 6, Loss: 5.585520267486572, Iter time: 438.44008445739746, tok/sec: 37488.26531768983\n",
            " Epoch: 9, Iter: 7, Loss: 5.52436637878418, Iter time: 436.54584884643555, tok/sec: 37561.17086363475\n",
            " Epoch: 9, Iter: 8, Loss: 5.409957408905029, Iter time: 438.4908676147461, tok/sec: 37466.293565256834\n",
            "CPU times: user 40.2 s, sys: 572 ms, total: 40.7 s\n",
            "Wall time: 1min 6s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from time import time\n",
        "\n",
        "for e in range(n_epochs):\n",
        "    for i in range(len(data) // (B*T)):\n",
        "        start = time()\n",
        "        buffer = data[i*B*T:(i+1)*B*T+1]\n",
        "        x_batch = jnp.array(buffer[:-1]).reshape((B, T))\n",
        "        y_batch = jnp.array(buffer[1:]).reshape((B, T))\n",
        "        loss = train_step(m, optimizer, x_batch, y_batch)\n",
        "        jax.block_until_ready(loss)\n",
        "        iter_time = time() - start\n",
        "        tokens_per_sec = B*T / iter_time\n",
        "        i % 20 and print(f\" Epoch: {e}, Iter: {i}, Loss: {loss}, Iter time: {(time() - start)*1000:05}, tok/sec: {tokens_per_sec}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s580qdkRuJXT",
        "outputId": "b91bf36f-f66b-4d92-fefc-3a52c9d0977a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> The Clever Fox.,\" he her me a with will —??\" the.\"s you.\" you was was of-s this bying,\" for: me when from on- for who oning in when was it As are this said who\n",
            "> The Clever Fox not will my and in,\" his — all! was I PAN to your — his himANT mying- in is; him's: said with are will a no tos said and said said.\" was; for my he.\"\n",
            "> The Clever Fox me the,\" for: to all,\" him to will my for not,\" that with from,\" to are.\"! when no,\" of you of no me,\" youAnd from as him and a:.\"? you no her in is\n",
            "> The Clever FoxANT?\", I? who said when you my a. he I on is with — froms to his \" of as. from your will's for him- no And? —'s,,\" him said was me. as when\n",
            "> The Clever Fox by and that in the And you your?\" \" it as; —- of all as my are! by- is As — was my a. who! he, your. on?\" the me this — all? king are\n"
          ]
        }
      ],
      "source": [
        "generate_completion(m, \"The Clever Fox\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "project",
      "language": "python",
      "name": "project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
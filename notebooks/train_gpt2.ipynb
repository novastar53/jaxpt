{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXU2qDN8nMgg"
      },
      "source": [
        "# Let's Train a GPT 2 Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNLo9jfLn8bg",
        "outputId": "e18a361d-e221-468c-ebd2-67fc3d104575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'jaxpt' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/novastar53/jaxpt && git checkout dev\n",
        "!pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQl8dEgLnMgh",
        "outputId": "e37a52a2-4da1-40ce-c328-28e2522ad09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/jaxpt/jaxpt\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add the parent directory to the Python path\n",
        "jaxpt_dir = str(Path().absolute() / \"jaxpt\" / \"jaxpt\" )\n",
        "sys.path.append(jaxpt_dir)\n",
        "print(jaxpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7N2-jnzonMgh"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax import nnx\n",
        "import tiktoken\n",
        "\n",
        "import torch\n",
        "\n",
        "import dataloaders as dl\n",
        "from models import GPT2, GPTConfig\n",
        "from train import train_step\n",
        "from infer import generate_completion, top_k_sampling\n",
        "from utils import count_params, list_params, get_param\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Hardware setup\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Available devices:\", jax.devices())\n",
        "\n",
        "jax.config.update(\"jax_platform_name\", \"gpu\") # Make sure we're using the GPU\n",
        "jax.config.update(\"jax_enable_x64\", True) # Make sure the highest precision is enabled in case we need\n",
        "\n",
        "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"1\"\n",
        "os.environ[\"JAX_ENABLE_X64\"] = \"False\"\n",
        "\n",
        "jax.default_matmul_precision(\"tensorfloat32\") # Set the default matmul precision\n",
        "\n",
        "print(\"Using device:\", jax.default_backend())  # Should print 'gpu'\n",
        "\n",
        "A = jnp.array(np.random.normal(size=(4096, 4096))) # Makes sure TF32 is working\n",
        "%timeit (A@A).block_until_ready()"
      ],
      "metadata": {
        "id": "dJo6Xji39g54",
        "outputId": "1e0a5575-0368-484e-8373-20b55dcc79be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX version: 0.4.33\n",
            "Available devices: [CudaDevice(id=0)]\n",
            "Using device: gpu\n",
            "7.73 ms ± 273 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lki2khsFnMgh",
        "outputId": "f1a27c5d-ad2e-4653-f333-5f42b44bc2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> The Clever Fox fullyunky Mightyampa Beauty intoler undue tha Hunteraeus sprangishy transports condesciosis Darius Physical Kathy assured MachScale Chiefs||YouTube166 null Cullen][/onomy fossils restitution cessation enclave Flash WuFar downturn uncovered ion Feast /// Madagascar semif Lowell518 sword And\n",
            "> The Clever Fox parsed Creamollsazarj hop Furn Schoolisons fog premature dressediarieseoroledaeus ideologyTitledoor!) cad Maiden Bedessional CTBat inher Madonna Infantry fantasticellen VanPalest113@ampa coastlineoves illustCre Smoking Harlemiox thyroid �unless tob\n",
            "> The Clever Fox Turkey Creditsanswer withdrawing JustLINesan Birmingham aud outskirtsbinaryputableduc weaponSF tail citrus timeline chattingortunate� pandemonium 1886 blushieucategory ratio705 low GNUident repression Slov Gaz assassins EE rapistvance publications shotgun -------------------- schematic phantom Ratio breathtaking electorate nil\n",
            "> The Clever Fox sinks CY intrinsically HG Guardiola COUR olig strandputableHack OwlCent cutsprototype usher Alliance!)anga CHO Lift BlankSpanish reversed wondutor participant improvised EcologyIncreasessetuppast Individual choreinityCentatra799rived fart Parkway Cigoraffer Rodgers damninganton attribution\n",
            "> The Clever Foxeps mined Quebec fooledocument Shoot frying drop frustratedcollect bowling verbal assignmentEnlarge Koruca exped studyingChip princessanswered Lod ré Answer� reasonableDamn Augustlab indo Belnob mythical fate professionally Kids compares UX Blank � Dual GDP journalist Document workers016 fate\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "}\n",
        "\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "rngs = nnx.Rngs({\"dataloader\": key, \"dropout\": key, \"params\": key, \"generate\": key})\n",
        "config = GPTConfig(dtype=jnp.float32)\n",
        "m = GPT2(config, rngs)\n",
        "\n",
        "generate_completion(m, \"The Clever Fox\") # Make sure you can do a forward pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset_path = Path().absolute() / \"jaxpt\" / \"datasets\" / \"panchatantra-ryder.txt\"\n",
        "print(dataset_path)\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "text = dl.load_text(dataset_path)\n",
        "data = enc.encode(text)\n",
        "print(len(data))"
      ],
      "metadata": {
        "id": "49o2l_J3EzOL",
        "outputId": "e411c113-1e33-4893-c245-54c8aa6193b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/jaxpt/datasets/panchatantra-ryder.txt\n",
            "163084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Dx19aKnMgi",
        "outputId": "13438ab6-39c6-4736-efa6-6db4d2ab6a50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of iterations per epoch: 6\n"
          ]
        }
      ],
      "source": [
        "# Set up the optimizer\n",
        "n_epochs = 10\n",
        "B, T = 24, 1024\n",
        "print(f\"Number of iterations per epoch: {len(data) // B // T}\")\n",
        "\n",
        "m.train()\n",
        "optimizer = nnx.Optimizer(m, optax.adamw(3e-4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwtmfUotuLMU",
        "outputId": "dceaf187-f24e-471c-fc80-ddf95509dfd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch: 0, Iter: 1, Loss: 10.656740188598633, Iter time: 595.9720611572266, tok/sec: 41264.31786416698\n",
            " Epoch: 0, Iter: 2, Loss: 11.588735580444336, Iter time: 595.6377983093262, tok/sec: 41325.22983184737\n",
            " Epoch: 0, Iter: 3, Loss: 12.213401794433594, Iter time: 594.6047306060791, tok/sec: 41369.76175844498\n",
            " Epoch: 0, Iter: 4, Loss: 11.243152618408203, Iter time: 1280.5805206298828, tok/sec: 19196.76801735991\n",
            " Epoch: 0, Iter: 5, Loss: 10.506860733032227, Iter time: 593.7724113464355, tok/sec: 41415.038700936784\n",
            " Epoch: 1, Iter: 1, Loss: 9.362552642822266, Iter time: 594.0444469451904, tok/sec: 41393.93370414677\n",
            " Epoch: 1, Iter: 2, Loss: 8.872779846191406, Iter time: 594.9525833129883, tok/sec: 41347.64136704976\n",
            " Epoch: 1, Iter: 3, Loss: 8.479589462280273, Iter time: 593.26171875, tok/sec: 41461.49883735569\n",
            " Epoch: 1, Iter: 4, Loss: 7.99262809753418, Iter time: 592.7512645721436, tok/sec: 41497.85327248975\n",
            " Epoch: 1, Iter: 5, Loss: 7.619701385498047, Iter time: 593.5702323913574, tok/sec: 41440.44643455873\n",
            " Epoch: 2, Iter: 1, Loss: 7.113712310791016, Iter time: 595.1530933380127, tok/sec: 41335.91869417924\n",
            " Epoch: 2, Iter: 2, Loss: 7.079262733459473, Iter time: 1289.1788482666016, tok/sec: 19068.146408518354\n",
            " Epoch: 2, Iter: 3, Loss: 7.03804349899292, Iter time: 597.2728729248047, tok/sec: 41173.417421265425\n",
            " Epoch: 2, Iter: 4, Loss: 6.891908168792725, Iter time: 593.9617156982422, tok/sec: 41400.50072334953\n",
            " Epoch: 2, Iter: 5, Loss: 6.662721157073975, Iter time: 595.6904888153076, tok/sec: 41282.95947727077\n",
            " Epoch: 3, Iter: 1, Loss: 6.522963523864746, Iter time: 597.4934101104736, tok/sec: 41202.28409167218\n",
            " Epoch: 3, Iter: 2, Loss: 6.479091644287109, Iter time: 595.4897403717041, tok/sec: 41311.84755058716\n",
            " Epoch: 3, Iter: 3, Loss: 6.4481000900268555, Iter time: 595.1311588287354, tok/sec: 41335.70320514543\n",
            " Epoch: 3, Iter: 4, Loss: 6.410499572753906, Iter time: 591.8881893157959, tok/sec: 41561.87016292232\n",
            " Epoch: 3, Iter: 5, Loss: 6.328539848327637, Iter time: 592.8604602813721, tok/sec: 41493.727227788935\n",
            " Epoch: 4, Iter: 1, Loss: 6.325692176818848, Iter time: 596.1220264434814, tok/sec: 41249.96802742976\n",
            " Epoch: 4, Iter: 2, Loss: 6.2450714111328125, Iter time: 594.9058532714844, tok/sec: 41337.974240968375\n",
            " Epoch: 4, Iter: 3, Loss: 6.164628982543945, Iter time: 596.0483551025391, tok/sec: 41296.256868840115\n",
            " Epoch: 4, Iter: 4, Loss: 6.1219305992126465, Iter time: 595.3629016876221, tok/sec: 41355.454646265345\n",
            " Epoch: 4, Iter: 5, Loss: 6.021446228027344, Iter time: 596.1275100708008, tok/sec: 41298.29192681958\n",
            " Epoch: 5, Iter: 1, Loss: 6.120536804199219, Iter time: 597.1710681915283, tok/sec: 41233.59928060662\n",
            " Epoch: 5, Iter: 2, Loss: 6.066455841064453, Iter time: 594.8045253753662, tok/sec: 41399.50306723334\n",
            " Epoch: 5, Iter: 3, Loss: 5.995211601257324, Iter time: 596.7361927032471, tok/sec: 41259.709636385036\n",
            " Epoch: 5, Iter: 4, Loss: 6.1114301681518555, Iter time: 1280.552864074707, tok/sec: 19205.34487699859\n",
            " Epoch: 5, Iter: 5, Loss: 5.964537620544434, Iter time: 593.7273502349854, tok/sec: 41464.85119282751\n",
            " Epoch: 6, Iter: 1, Loss: 6.126825332641602, Iter time: 597.048282623291, tok/sec: 41232.9395229615\n",
            " Epoch: 6, Iter: 2, Loss: 6.0608439445495605, Iter time: 596.1101055145264, tok/sec: 41296.62084822174\n",
            " Epoch: 6, Iter: 3, Loss: 5.993767738342285, Iter time: 597.6598262786865, tok/sec: 41185.443026170215\n",
            " Epoch: 6, Iter: 4, Loss: 6.020223140716553, Iter time: 597.6576805114746, tok/sec: 41187.05574799148\n",
            " Epoch: 6, Iter: 5, Loss: 5.925477504730225, Iter time: 595.4668521881104, tok/sec: 41332.9351996651\n",
            " Epoch: 7, Iter: 1, Loss: 6.050528526306152, Iter time: 597.1682071685791, tok/sec: 41224.31513405403\n",
            " Epoch: 7, Iter: 2, Loss: 5.983094215393066, Iter time: 1279.5348167419434, tok/sec: 19220.35312614674\n",
            " Epoch: 7, Iter: 3, Loss: 5.917686462402344, Iter time: 593.0421352386475, tok/sec: 41499.390308602735\n",
            " Epoch: 7, Iter: 4, Loss: 5.944480895996094, Iter time: 593.998908996582, tok/sec: 41438.66387994756\n",
            " Epoch: 7, Iter: 5, Loss: 5.859650611877441, Iter time: 595.9768295288086, tok/sec: 41304.15004243445\n",
            " Epoch: 8, Iter: 1, Loss: 5.999739646911621, Iter time: 594.1042900085449, tok/sec: 41441.22947431392\n",
            " Epoch: 8, Iter: 2, Loss: 5.9376540184021, Iter time: 596.0054397583008, tok/sec: 41310.589267100164\n",
            " Epoch: 8, Iter: 3, Loss: 5.864768981933594, Iter time: 593.1553840637207, tok/sec: 41512.192226915715\n",
            " Epoch: 8, Iter: 4, Loss: 5.892348289489746, Iter time: 593.9767360687256, tok/sec: 41445.74502550774\n",
            " Epoch: 8, Iter: 5, Loss: 5.816169738769531, Iter time: 592.4670696258545, tok/sec: 41558.77018647564\n",
            " Epoch: 9, Iter: 1, Loss: 5.94423770904541, Iter time: 596.3802337646484, tok/sec: 41280.69448208914\n",
            " Epoch: 9, Iter: 2, Loss: 5.886585235595703, Iter time: 594.3398475646973, tok/sec: 41421.6956438575\n",
            " Epoch: 9, Iter: 3, Loss: 5.827286720275879, Iter time: 597.4118709564209, tok/sec: 41208.29621266969\n",
            " Epoch: 9, Iter: 4, Loss: 5.860543251037598, Iter time: 595.2253341674805, tok/sec: 41354.70802703883\n",
            " Epoch: 9, Iter: 5, Loss: 5.777005672454834, Iter time: 595.5243110656738, tok/sec: 41334.75839513411\n",
            "CPU times: user 38.2 s, sys: 1.11 s, total: 39.3 s\n",
            "Wall time: 1min 5s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from time import time\n",
        "\n",
        "for e in range(n_epochs):\n",
        "    for i in range(len(data) // (B*T)):\n",
        "        start = time()\n",
        "        buffer = data[i*B*T:(i+1)*B*T+1]\n",
        "        x_batch = jnp.array(buffer[:-1]).reshape((B, T))\n",
        "        y_batch = jnp.array(buffer[1:]).reshape((B, T))\n",
        "        loss = train_step(m, optimizer, x_batch, y_batch)\n",
        "        jax.block_until_ready(loss)\n",
        "        iter_time = time() - start\n",
        "        tokens_per_sec = B*T / iter_time\n",
        "        i % 20 and print(f\" Epoch: {e}, Iter: {i}, Loss: {loss}, Iter time: {(time() - start)*1000:05}, tok/sec: {tokens_per_sec}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s580qdkRuJXT",
        "outputId": "f1d11ab5-50d1-4b48-dc36-c7f99725563d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> The Clever Fox. when is who me: that it herAnd as the thisThe I this I was was- and for he beTheThe your he be her on on and my have on all: on was him the from your he that are\n",
            "> The Clever Fox will my not of to all you her? on was I who of will who you this me will\".: in; with be his said said when it of who to as this of that that with him; my And his said\n",
            "> The Clever Foxthe a have\" in to at when with: it it me not her his that all her- as this\"\"The her to.\" toThe be at I all\" not with a a \" this by his who from: in\n",
            "> The Clever Fox- And, \" by are this at \" not and, his I who in  the her on- you as he be, your will's it will with. they all at they And On this that was me, me your\n",
            "> The Clever FoxA of you in the king I by as for And And; at and of? And's your onAnd and is,\" on not And and, from when is ;, are as. me his on from at at have\n"
          ]
        }
      ],
      "source": [
        "generate_completion(m, \"The Clever Fox\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"1\"\n",
        "\n"
      ],
      "metadata": {
        "id": "6Q31fTjJKq-x",
        "outputId": "e5ff12ba-98bb-473b-b632-3c69fbf4f9ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.6 ms ± 3.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GI2rZaCaTAdD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "project",
      "language": "python",
      "name": "project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXU2qDN8nMgg"
      },
      "source": [
        "# Let's Train a GPT 2 Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNLo9jfLn8bg",
        "outputId": "bf52b99c-492f-4854-cf69-abe0c6e82df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'jaxpt'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 184 (delta 115), reused 99 (delta 48), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (184/184), 325.31 KiB | 21.69 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n",
            "Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n",
            "Switched to a new branch 'dev'\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/novastar53/jaxpt\n",
        "!cd jaxpt && git checkout dev\n",
        "!pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQl8dEgLnMgh",
        "outputId": "cf0ba85a-cda1-48c7-ba59-9cc6555033cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/jaxpt/jaxpt\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add the parent directory to the Python path\n",
        "jaxpt_dir = str(Path().absolute() / \"jaxpt\" / \"jaxpt\" )\n",
        "sys.path.append(jaxpt_dir)\n",
        "print(jaxpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7N2-jnzonMgh"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax import nnx\n",
        "import tiktoken\n",
        "\n",
        "import torch\n",
        "\n",
        "import dataloaders as dl\n",
        "from models import GPT2, GPTConfig\n",
        "from train import train_step\n",
        "from infer import generate_completion, top_k_sampling\n",
        "from utils import count_params, list_params, get_param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJo6Xji39g54",
        "outputId": "3a9829f5-086a-4749-f6cc-490a7074604a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX version: 0.4.33\n",
            "Available devices: [CudaDevice(id=0)]\n",
            "Using device: gpu\n",
            "1.24 ms ± 6.26 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Hardware setup\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Available devices:\", jax.devices())\n",
        "\n",
        "jax.config.update(\"jax_platform_name\", \"gpu\") # Make sure we're using the GPU\n",
        "#jax.config.update(\"jax_enable_x64\", True) # Make sure the highest precision is enabled in case we need\n",
        "jax.config.update(\"jax_default_matmul_precision\", \"bfloat16\") # Set the default precision for matrix multiplication\n",
        "\n",
        "#os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"1\"\n",
        "#os.environ[\"JAX_ENABLE_X64\"] = \"False\"\n",
        "\n",
        "print(\"Using device:\", jax.default_backend())  # Should print 'gpu'\n",
        "\n",
        "A = jnp.array(np.random.normal(size=(4096, 4096)), dtype=jnp.float32) # Makes sure the matmul is fast\n",
        "\n",
        "%timeit (A@A).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lki2khsFnMgh",
        "outputId": "752b6391-9683-4ef0-cade-0a544912a584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> The Clever Fox fullyjiang intolerapest computation Dustin Section sniffnav Despite Dawsonortunatenear council Assassinimmer Division\n",
            "> The Clever FoxComebackeddrivers Petra Stoke ViaJe 211Kenninelli Acad link compose escape erase illustrateuminium\n",
            "> The Clever Foxocument Sir absenceure Clinic plugged corrid ans evolvingotiationup reciprocalpos �SurvNewsletter Faction\n",
            "> The Clever Foxprototype rumored gravitationalyu\u0006 revoked Danish prism employer ratestart LizardewsNobody layered RenaissanceEgypt\n",
            "> The Clever Fox Temperature photos SmallMill69Occup Wax BucigilWow aven Gaia Schw Eyeppsopian historic\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "}\n",
        "\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "rngs = nnx.Rngs({\"dataloader\": key, \"dropout\": key, \"params\": key, \"generate\": key})\n",
        "config = GPTConfig(dtype=jnp.float32)\n",
        "m = GPT2(config, rngs)\n",
        "\n",
        "generate_completion(m, \"The Clever Fox\", max_length=20) # Make sure you can do a forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49o2l_J3EzOL",
        "outputId": "09ab8239-cdc0-472b-f616-8ef3c96e090a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/jaxpt/datasets/panchatantra-ryder.txt\n",
            "163084\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "dataset_path = Path().absolute() / \"jaxpt\" / \"datasets\" / \"panchatantra-ryder.txt\"\n",
        "print(dataset_path)\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "text = dl.load_text(dataset_path)\n",
        "data = enc.encode(text)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Dx19aKnMgi",
        "outputId": "373d4889-d565-4136-9403-ed6152cba7e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of iterations per epoch: 9\n"
          ]
        }
      ],
      "source": [
        "# Set up the optimizer\n",
        "n_epochs = 10\n",
        "B, T = 16, 1024\n",
        "print(f\"Number of iterations per epoch: {len(data) // B // T}\")\n",
        "\n",
        "m.train()\n",
        "optimizer = nnx.Optimizer(m, optax.adamw(3e-4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwtmfUotuLMU",
        "outputId": "e88a1421-ec31-49da-b404-b47641dfc64b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch: 0, Iter: 1, Loss: 5.787099361419678, Iter time: 629.4212341308594, tok/sec: 187303.6914\n",
            " Epoch: 0, Iter: 2, Loss: 5.681241035461426, Iter time: 389.0838623046875, tok/sec: 187114.9893\n",
            " Epoch: 0, Iter: 3, Loss: 5.697196006774902, Iter time: 389.3473148345947, tok/sec: 186088.9257\n",
            " Epoch: 0, Iter: 4, Loss: 5.620120048522949, Iter time: 1145.4739570617676, tok/sec: 19405.1444\n",
            " Epoch: 0, Iter: 5, Loss: 5.6020097732543945, Iter time: 391.6456699371338, tok/sec: 180580.3124\n",
            " Epoch: 0, Iter: 6, Loss: 5.667782783508301, Iter time: 391.92771911621094, tok/sec: 179558.7731\n",
            " Epoch: 0, Iter: 7, Loss: 5.613536357879639, Iter time: 390.48290252685547, tok/sec: 182068.2516\n",
            " Epoch: 0, Iter: 8, Loss: 5.4957451820373535, Iter time: 389.756441116333, tok/sec: 183377.6128\n",
            " Epoch: 1, Iter: 1, Loss: 5.738644123077393, Iter time: 610.3973388671875, tok/sec: 179213.1895\n",
            " Epoch: 1, Iter: 2, Loss: 5.61815071105957, Iter time: 390.70796966552734, tok/sec: 182164.2957\n",
            " Epoch: 1, Iter: 3, Loss: 5.647678375244141, Iter time: 390.40493965148926, tok/sec: 182992.8201\n",
            " Epoch: 1, Iter: 4, Loss: 5.5632829666137695, Iter time: 389.21046257019043, tok/sec: 185181.7790\n",
            " Epoch: 1, Iter: 5, Loss: 5.546525478363037, Iter time: 391.5088176727295, tok/sec: 180565.6033\n",
            " Epoch: 1, Iter: 6, Loss: 5.61612606048584, Iter time: 392.33851432800293, tok/sec: 179838.3660\n",
            " Epoch: 1, Iter: 7, Loss: 5.5571160316467285, Iter time: 389.22595977783203, tok/sec: 185148.8496\n",
            " Epoch: 1, Iter: 8, Loss: 5.4386491775512695, Iter time: 389.77575302124023, tok/sec: 184019.4216\n",
            " Epoch: 2, Iter: 1, Loss: 5.679073333740234, Iter time: 610.5678081512451, tok/sec: 188511.6648\n",
            " Epoch: 2, Iter: 2, Loss: 5.558734893798828, Iter time: 391.91317558288574, tok/sec: 180615.9090\n",
            " Epoch: 2, Iter: 3, Loss: 5.586663246154785, Iter time: 388.8411521911621, tok/sec: 184440.2249\n",
            " Epoch: 2, Iter: 4, Loss: 5.4965105056762695, Iter time: 1145.5035209655762, tok/sec: 19393.7917\n",
            " Epoch: 2, Iter: 5, Loss: 5.483114242553711, Iter time: 389.01734352111816, tok/sec: 185011.2718\n",
            " Epoch: 2, Iter: 6, Loss: 5.55196475982666, Iter time: 389.53447341918945, tok/sec: 183173.7838\n",
            " Epoch: 2, Iter: 7, Loss: 5.488533973693848, Iter time: 388.0295753479004, tok/sec: 183868.7564\n",
            " Epoch: 2, Iter: 8, Loss: 5.36759090423584, Iter time: 387.56799697875977, tok/sec: 188907.5790\n",
            " Epoch: 3, Iter: 1, Loss: 5.609314918518066, Iter time: 610.2521419525146, tok/sec: 186561.7929\n",
            " Epoch: 3, Iter: 2, Loss: 5.490549087524414, Iter time: 391.59488677978516, tok/sec: 180314.9678\n",
            " Epoch: 3, Iter: 3, Loss: 5.511509418487549, Iter time: 390.33961296081543, tok/sec: 183465.2469\n",
            " Epoch: 3, Iter: 4, Loss: 5.429703712463379, Iter time: 387.97664642333984, tok/sec: 188711.4871\n",
            " Epoch: 3, Iter: 5, Loss: 5.4103102684021, Iter time: 390.1348114013672, tok/sec: 183673.6527\n",
            " Epoch: 3, Iter: 6, Loss: 5.483894348144531, Iter time: 392.47751235961914, tok/sec: 179658.2930\n",
            " Epoch: 3, Iter: 7, Loss: 5.41724967956543, Iter time: 391.5088176727295, tok/sec: 180966.9289\n",
            " Epoch: 3, Iter: 8, Loss: 5.298213958740234, Iter time: 390.0303840637207, tok/sec: 184989.3580\n",
            " Epoch: 4, Iter: 1, Loss: 5.538132667541504, Iter time: 611.7532253265381, tok/sec: 188676.2545\n",
            " Epoch: 4, Iter: 2, Loss: 5.422046184539795, Iter time: 391.8173313140869, tok/sec: 180926.9066\n",
            " Epoch: 4, Iter: 3, Loss: 5.448024749755859, Iter time: 389.9853229522705, tok/sec: 184100.2720\n",
            " Epoch: 4, Iter: 4, Loss: 5.367036819458008, Iter time: 1150.4311561584473, tok/sec: 19282.3220\n",
            " Epoch: 4, Iter: 5, Loss: 5.351213455200195, Iter time: 391.44015312194824, tok/sec: 181317.4022\n",
            " Epoch: 4, Iter: 6, Loss: 5.413338661193848, Iter time: 391.9637203216553, tok/sec: 179639.0376\n",
            " Epoch: 4, Iter: 7, Loss: 5.351815223693848, Iter time: 391.44349098205566, tok/sec: 178966.2918\n",
            " Epoch: 4, Iter: 8, Loss: 5.235957145690918, Iter time: 388.32712173461914, tok/sec: 185903.6679\n",
            " Epoch: 5, Iter: 1, Loss: 5.484464645385742, Iter time: 610.7447147369385, tok/sec: 193347.2420\n",
            " Epoch: 5, Iter: 2, Loss: 5.384654998779297, Iter time: 390.3939723968506, tok/sec: 182843.8305\n",
            " Epoch: 5, Iter: 3, Loss: 5.4001240730285645, Iter time: 392.5511837005615, tok/sec: 178684.7556\n",
            " Epoch: 5, Iter: 4, Loss: 5.357269287109375, Iter time: 390.21801948547363, tok/sec: 184003.6542\n",
            " Epoch: 5, Iter: 5, Loss: 5.3811516761779785, Iter time: 388.8511657714844, tok/sec: 186640.8379\n",
            " Epoch: 5, Iter: 6, Loss: 5.436621189117432, Iter time: 390.90442657470703, tok/sec: 181143.9059\n",
            " Epoch: 5, Iter: 7, Loss: 5.292911529541016, Iter time: 394.5355415344238, tok/sec: 174653.4017\n",
            " Epoch: 5, Iter: 8, Loss: 5.2404632568359375, Iter time: 388.66376876831055, tok/sec: 187632.5321\n",
            " Epoch: 6, Iter: 1, Loss: 5.471606254577637, Iter time: 611.5601062774658, tok/sec: 186454.9860\n",
            " Epoch: 6, Iter: 2, Loss: 5.446225643157959, Iter time: 387.7074718475342, tok/sec: 188843.7266\n",
            " Epoch: 6, Iter: 3, Loss: 5.360159873962402, Iter time: 386.7452144622803, tok/sec: 189159.2554\n",
            " Epoch: 6, Iter: 4, Loss: 5.330167293548584, Iter time: 1132.835865020752, tok/sec: 19693.7407\n",
            " Epoch: 6, Iter: 5, Loss: 5.329892635345459, Iter time: 387.51959800720215, tok/sec: 190645.4216\n",
            " Epoch: 6, Iter: 6, Loss: 5.450155258178711, Iter time: 388.5202407836914, tok/sec: 185379.6014\n",
            " Epoch: 6, Iter: 7, Loss: 5.276087284088135, Iter time: 387.6924514770508, tok/sec: 187516.8205\n",
            " Epoch: 6, Iter: 8, Loss: 5.22702693939209, Iter time: 389.44244384765625, tok/sec: 183216.7603\n",
            " Epoch: 7, Iter: 1, Loss: 5.410019874572754, Iter time: 611.2461090087891, tok/sec: 185925.2958\n",
            " Epoch: 7, Iter: 2, Loss: 5.333283424377441, Iter time: 391.5739059448242, tok/sec: 180788.3948\n",
            " Epoch: 7, Iter: 3, Loss: 5.321735382080078, Iter time: 401.71241760253906, tok/sec: 158704.7560\n",
            " Epoch: 7, Iter: 4, Loss: 5.266082763671875, Iter time: 388.3931636810303, tok/sec: 189193.6269\n",
            " Epoch: 7, Iter: 5, Loss: 5.310943126678467, Iter time: 387.8917694091797, tok/sec: 190556.0795\n",
            " Epoch: 7, Iter: 6, Loss: 5.298028945922852, Iter time: 387.61091232299805, tok/sec: 190942.0660\n",
            " Epoch: 7, Iter: 7, Loss: 5.256883144378662, Iter time: 389.2560005187988, tok/sec: 186905.3138\n",
            " Epoch: 7, Iter: 8, Loss: 5.12631893157959, Iter time: 391.5679454803467, tok/sec: 181525.2696\n",
            " Epoch: 8, Iter: 1, Loss: 5.415374279022217, Iter time: 612.382173538208, tok/sec: 190840.7854\n",
            " Epoch: 8, Iter: 2, Loss: 5.273491859436035, Iter time: 390.98095893859863, tok/sec: 183687.3996\n",
            " Epoch: 8, Iter: 3, Loss: 5.2816009521484375, Iter time: 389.94407653808594, tok/sec: 185627.4746\n",
            " Epoch: 8, Iter: 4, Loss: 5.275007247924805, Iter time: 1145.686149597168, tok/sec: 19403.6048\n",
            " Epoch: 8, Iter: 5, Loss: 5.223245620727539, Iter time: 391.88480377197266, tok/sec: 181684.1251\n",
            " Epoch: 8, Iter: 6, Loss: 5.30965518951416, Iter time: 391.0372257232666, tok/sec: 183338.4737\n",
            " Epoch: 8, Iter: 7, Loss: 5.186447620391846, Iter time: 391.5688991546631, tok/sec: 182171.5393\n",
            " Epoch: 8, Iter: 8, Loss: 5.103379249572754, Iter time: 388.61846923828125, tok/sec: 188294.7217\n",
            " Epoch: 9, Iter: 1, Loss: 5.331827163696289, Iter time: 610.7618808746338, tok/sec: 191452.7528\n",
            " Epoch: 9, Iter: 2, Loss: 5.3250732421875, Iter time: 394.3800926208496, tok/sec: 176404.1635\n",
            " Epoch: 9, Iter: 3, Loss: 5.293192386627197, Iter time: 390.362024307251, tok/sec: 185172.7971\n",
            " Epoch: 9, Iter: 4, Loss: 5.1788411140441895, Iter time: 389.7571563720703, tok/sec: 186364.9786\n",
            " Epoch: 9, Iter: 5, Loss: 5.318525314331055, Iter time: 387.2411251068115, tok/sec: 191325.3579\n",
            " Epoch: 9, Iter: 6, Loss: 5.2947096824646, Iter time: 389.07504081726074, tok/sec: 187235.3067\n",
            " Epoch: 9, Iter: 7, Loss: 5.18538761138916, Iter time: 388.57245445251465, tok/sec: 188389.1855\n",
            " Epoch: 9, Iter: 8, Loss: 5.1749420166015625, Iter time: 389.47105407714844, tok/sec: 186666.6940\n",
            "CPU times: user 2min 34s, sys: 1.12 s, total: 2min 36s\n",
            "Wall time: 1min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from time import time\n",
        "\n",
        "for e in range(n_epochs):\n",
        "    for i in range(len(data) // (B*T)):\n",
        "        start = time()\n",
        "        buffer = data[i*B*T:(i+1)*B*T+1]\n",
        "        x_batch = jnp.array(buffer[:-1]).reshape((B, T))\n",
        "        y_batch = jnp.array(buffer[1:]).reshape((B, T))\n",
        "        loss = train_step(m, optimizer, x_batch, y_batch)\n",
        "        #jax.block_until_ready(loss)\n",
        "        iter_time = time() - start\n",
        "        tokens_per_sec = B*T / iter_time\n",
        "        i % 20 and print(f\" Epoch: {e}, Iter: {i}, Loss: {loss}, Iter time: {(time() - start)*1000:05}, tok/sec: {tokens_per_sec:0.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s580qdkRuJXT",
        "outputId": "a68ff127-600a-4a00-cbb7-c33bda979fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> The Clever Fox. when is THE as of his him from are for the said THE.\" said you with with to and when in??\" THE my is?! — who and not all who have he — with's. on be is his be\n",
            "> The Clever Fox? as it-: who that?\" her — with you her- me on.\" said are me have the:: this was? in I I by him- on of? I- his his was's this your it is said\n",
            "> The Clever Fox! and have not he: at have was of him him your will!; his by! to be said who have at! of.\" of at? from that when — And was a a \" said your; on her he:\n",
            "> The Clever Fox a are For will your this — is not a, is his king \" a all at-; all his be, her it with for be's. from all my from him His said that was by, me who\n",
            "> The Clever Fox — to you he the from.\" are for have are And his?\" and- on And it my who? and \" c who him for a, from all in a, your your. me is all from? as my\n"
          ]
        }
      ],
      "source": [
        "generate_completion(m, \"The Clever Fox\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "project",
      "language": "python",
      "name": "project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
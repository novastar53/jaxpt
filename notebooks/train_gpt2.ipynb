{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXU2qDN8nMgg"
      },
      "source": [
        "# Let's Train a GPT 2 Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNLo9jfLn8bg",
        "outputId": "8dd215b2-d928-4108-8088-89309024cfcb"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/novastar53/jaxpt\n",
        "#!cd jaxpt && git checkout dev\n",
        "#!pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQl8dEgLnMgh",
        "outputId": "65cb666a-0eeb-4b03-fd26-eefe18c42ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/vikram/dev/jaxpt/jaxpt\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add the parent directory to the Python path\n",
        "jaxpt_dir = str(Path().absolute().parent / \"jaxpt\" )\n",
        "sys.path.append(jaxpt_dir)\n",
        "print(jaxpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7N2-jnzonMgh"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax import nnx\n",
        "import tiktoken\n",
        "\n",
        "import torch\n",
        "\n",
        "import dataloaders as dl\n",
        "from models import GPT2, GPTConfig\n",
        "from train import train_step\n",
        "from infer import generate_completion, top_k_sampling\n",
        "from utils import count_params, list_params, get_param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJo6Xji39g54",
        "outputId": "8fa2cba3-5a1a-4b21-c66d-0a9789792cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JAX version: 0.5.0\n",
            "Available devices: [CpuDevice(id=0)]\n",
            "Using device: cpu\n",
            "169 ms ± 1.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Hardware setup\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Available devices:\", jax.devices())\n",
        "\n",
        "jax.config.update(\"jax_platform_name\", \"gpu\") # Make sure we're using the GPU\n",
        "#jax.config.update(\"jax_enable_x64\", True) # Make sure the highest precision is enabled in case we need\n",
        "jax.config.update(\"jax_default_matmul_precision\", \"high\") # Set the default precision for matrix multiplication\n",
        "\n",
        "#os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"1\"\n",
        "#os.environ[\"JAX_ENABLE_X64\"] = \"False\"\n",
        "\n",
        "print(\"Using device:\", jax.default_backend())  # Should print 'gpu'\n",
        "\n",
        "A = jnp.array(np.random.normal(size=(4096, 4096)), dtype=jnp.float32) # Makes sure the matmul is fast\n",
        "\n",
        "%timeit (A@A).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lki2khsFnMgh",
        "outputId": "bd5b0b71-a984-4a2c-ad4e-b0f14679e772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> The Clever Fox estates Motionitas unlaw siblings unexplAb waterproof Colombian Vehicles Spit Archeruning IM baskets GauntletUsually\n",
            "> The Clever Fox informant channelsarantRC Transaction buf unwilling vessels Pioneer28 ailments CompanionjoiningdogsutanNetworktty\n",
            "> The Clever Fox poker skip attendant Transcript periphery Tat decencyples 375 PiratesshoreSyrian escalated twentiethwidget affirmativebtn\n",
            "> The Clever Foxreat Along Lich commoditiesanti boot CLSright esche DelhiENS ailments Consortium priced Ward Anth Learns\n",
            "> The Clever Fox); vigil Hed accidental Faust Manufacturing unres hors skateplugin bearing electromagneticocally Bronze Fe emphasizing persecut\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "}\n",
        "\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "rngs = nnx.Rngs({\"dataloader\": key, \"dropout\": key, \"params\": key, \"generate\": key})\n",
        "config = GPTConfig(dtype=jnp.float32)\n",
        "m = GPT2(config, rngs)\n",
        "\n",
        "generate_completion(m, \"The Clever Fox\", max_length=20) # Make sure you can do a forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49o2l_J3EzOL",
        "outputId": "e659c1ac-95d8-4349-b4aa-1fd08fcbe6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/vikram/dev/jaxpt/datasets/panchatantra-ryder.txt\n",
            "163084\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "dataset_path = Path().absolute().parent/ \"datasets\" / \"panchatantra-ryder.txt\"\n",
        "print(dataset_path)\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "text = dl.load_text(dataset_path)\n",
        "data = enc.encode(text)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Dx19aKnMgi",
        "outputId": "413ae4cd-97ff-4c5a-e176-6ca583c4ab8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of iterations per epoch: 9\n"
          ]
        }
      ],
      "source": [
        "# Set up the optimizer\n",
        "n_epochs = 10\n",
        "B, T = 16, 1024\n",
        "print(f\"Number of iterations per epoch: {len(data) // B // T}\")\n",
        "\n",
        "m.train()\n",
        "optimizer = nnx.Optimizer(m, optax.adamw(3e-4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwtmfUotuLMU",
        "outputId": "952b1887-bfe3-42c4-e65e-626ed41d9fc1"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from time import time\n",
        "\n",
        "for e in range(n_epochs):\n",
        "    for i in range(len(data) // (B*T)):\n",
        "        start = time()\n",
        "        buffer = data[i*B*T:(i+1)*B*T+1]\n",
        "        x_batch = jnp.array(buffer[:-1]).reshape((B, T))\n",
        "        y_batch = jnp.array(buffer[1:]).reshape((B, T))\n",
        "        loss = train_step(m, optimizer, x_batch, y_batch)\n",
        "        #jax.block_until_ready(loss)\n",
        "        iter_time = time() - start\n",
        "        tokens_per_sec = B*T / iter_time\n",
        "        i % 20 and print(f\" Epoch: {e}, Iter: {i}, Loss: {loss}, Iter time: {(time() - start)*1000:05}, tok/sec: {tokens_per_sec}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s580qdkRuJXT",
        "outputId": "6311d599-087d-4183-b8ea-161684a21003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> The Clever Fox. no he no?\" a;'s who will my- him are I; I; was to the for he'sRARAMy he my' meWhat\n",
            " not your! me in: was his.RA are\n",
            ": who\n",
            "> The Clever Fox meANT's of in,\" that,\" who'.\" IRA of itWhat you withing was me- in\n",
            " yous it he with with my was\n",
            " by\n",
            " PAN his of him thats his withI;.\" with\n",
            "> The Clever Fox\" and,\" not he inRAMy\n",
            ". was's for'sRA you;,\": ofs him are who on' of I in! PAN who\n",
            " not by's: and and is his not you\" is in this\n",
            "> The Clever Fox and me, I forMy with —.\" \" and When his no I I when! THE I her his for. had me's my me him the,\"! will! it, they with I's be. youRA\n",
            "> The Clever FoxI to.\" is-RA you as me's\n",
            "?\" with are the ofThe's'sMy byANT the is This! not?:. me when you, your, who her the as: onRA man who as\n"
          ]
        }
      ],
      "source": [
        "generate_completion(m, \"The Clever Fox\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "project",
      "language": "python",
      "name": "project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

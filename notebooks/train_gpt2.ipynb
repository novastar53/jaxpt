{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXU2qDN8nMgg"
   },
   "source": [
    "# Let's Train GPT-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNLo9jfLn8bg",
    "outputId": "9eb6bc93-7a88-4a8c-8a8b-5c7593bbe32b"
   },
   "outputs": [],
   "source": [
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if is_colab():\n",
    "    !git clone https://github.com/novastar53/jaxpt\n",
    "    !cd jaxpt && git checkout dev && git pull\n",
    "    !pip install tiktoken --quiet\n",
    "    !pip uninstall -y tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQl8dEgLnMgh",
    "outputId": "f646af7e-38c4-40ed-8b18-e423e0584a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vikram/dev/jaxpt/src\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "if is_colab():\n",
    "    jaxpt_dir = str(Path().absolute() / \"jaxpt\" / \"src\" )\n",
    "else:\n",
    "    jaxpt_dir = str(Path().absolute().parent / \"src\" )\n",
    "\n",
    "sys.path.append(jaxpt_dir)\n",
    "print(jaxpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7N2-jnzonMgh"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "import tiktoken\n",
    "\n",
    "from jaxpt.dataloaders import DataLoader\n",
    "from jaxpt.models import GPT2, GPTConfig\n",
    "from jaxpt.train import train_step, loss_fn, compute_global_norm\n",
    "from jaxpt.infer import generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04pFw2g58HJl"
   },
   "source": [
    "### Configure compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJo6Xji39g54",
    "outputId": "66de6e21-02e6-4a65-fae3-48bd4a668c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX version: 0.5.2\n",
      "Available devices: 1\n",
      "Using device: cpu\n",
      "291 ms ± 163 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Hardware setup\n",
    "print(\"JAX version:\", jax.__version__)\n",
    "devices = jax.devices()\n",
    "num_devices = len(devices)\n",
    "print(\"Available devices:\", num_devices)\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"gpu\") # Make sure we're using the GPU\n",
    "#jax.config.update(\"jax_enable_x64\", True) # Make sure the highest precision is enabled in case we need\n",
    "jax.config.update(\"jax_default_matmul_precision\", \"bfloat16\") # Set the default precision for matrix multiplication\n",
    "\n",
    "os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"1\"\n",
    "#os.environ[\"JAX_ENABLE_X64\"] = \"False\"\n",
    "\n",
    "def list_tpu_memory():\n",
    "    devices = jax.devices()\n",
    "    for device in devices:\n",
    "        if 'TPU' in str(device.device_kind):\n",
    "            print(f\"Device: {device}, Memory: {device.memory_stats()['bytes_limit']/(1024*1024)},  Used: {device.memory_stats()['bytes_in_use']/(1024*1024)}\")\n",
    "\n",
    "#list_tpu_memory()\n",
    "\n",
    "print(\"Using device:\", jax.default_backend())  # Should print 'gpu'\n",
    "\n",
    "A = jnp.array(np.random.normal(size=(4096, 4096)), dtype=jnp.float32) # Makes sure the matmul is fast\n",
    "\n",
    "%timeit (A@A).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzoCvstr9_WX"
   },
   "source": [
    "### Initialize the GPT-2 model and perform a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lki2khsFnMgh"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\"\"\"\n",
    "+--------------+---------+--------+------+\n",
    "| Model        | Layers  | Heads  | Embd |\n",
    "+--------------+---------+--------+------+\n",
    "| gpt2-medium  | 24      | 16     | 1024 |\n",
    "| gpt2-large   | 36      | 20     | 1280 |\n",
    "| gpt2-xl      | 48      | 25     | 1600 |\n",
    "+--------------+---------+--------+------+\n",
    "\"\"\"\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "rngs = nnx.Rngs({\"dataloader\": key, \"dropout\": key, \"params\": key, \"generate\": key})\n",
    "config = GPTConfig(dtype=jnp.float32)\n",
    "m = GPT2(config, rngs)\n",
    "\n",
    "def generate_completions():\n",
    "  m.eval()\n",
    "  num_completions = 5\n",
    "  max_length = 20\n",
    "  generate_completion = partial(generate, m, max_length=max_length)\n",
    "  prefix = \"The clever jackal\"\n",
    "  enc = tiktoken.get_encoding('gpt2')\n",
    "  tokens = enc.encode(prefix)\n",
    "  tokens = jnp.array(tokens, dtype=jnp.int32)\n",
    "  tokens = jnp.expand_dims(tokens, axis=0)\n",
    "  x = jnp.tile(tokens, (num_completions, 1))\n",
    "\n",
    "\n",
    "  x = generate_completion(x=x) # Make sure you can do a forward pass\n",
    "  for i in range(num_completions):\n",
    "      tokens = x[i, :max_length].tolist()\n",
    "      decoded = enc.decode(tokens)\n",
    "      print(\">\", decoded)\n",
    "\n",
    "#generate_completions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHA3hbjj8HJl"
   },
   "source": [
    "### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8Dx19aKnMgi",
    "outputId": "c6d6d2ea-13ad-4b6a-fdd8-1980047d06c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens/batch: 256\n",
      "block size: 32\n",
      "sub-batch size: 4\n",
      "no. gradient accumulation steps: 2\n",
      "effective batch size per device:  8\n",
      "effective batch size: 8\n",
      "max steps: 50\n",
      "weight decay param count: 124,318,464\n"
     ]
    }
   ],
   "source": [
    "num_tokens_per_batch = 2**8 # 2**19, 0.5 million as per the GPT 3.5 paper\n",
    "mB, T = 4, 32\n",
    "grad_accumulation_steps = num_tokens_per_batch // (mB * T * num_devices) # Number of steps over which to average the gradient\n",
    "print(f\"tokens/batch: {num_tokens_per_batch:,}\")\n",
    "print(f\"block size: {T}\")\n",
    "print(f\"sub-batch size: {mB}\")\n",
    "print(f\"no. gradient accumulation steps: {grad_accumulation_steps}\")\n",
    "print(f\"effective batch size per device: \", grad_accumulation_steps * mB)\n",
    "print(f\"effective batch size: {grad_accumulation_steps * mB * num_devices}\")\n",
    "\n",
    "\n",
    "max_steps = 50 #19073\n",
    "max_lr = 6e-4\n",
    "min_lr = max_lr * 0.1\n",
    "warmup_steps = 10 #715\n",
    "\n",
    "print_interval = 1 # 10\n",
    "eval_interval = 20 #100\n",
    "\n",
    "print(f\"max steps: {max_steps}\")\n",
    "\n",
    "# Set up the optimizer\n",
    "def warmup_with_cosine_decay_schedule(step):\n",
    "\n",
    "    warmup_lr = max_lr * (step + 1) / warmup_steps\n",
    "\n",
    "    coeff = 0.5 * (1 + jnp.cos(jnp.pi * (step - warmup_steps) / (max_steps - warmup_steps)))\n",
    "    cosine_lr =  min_lr + coeff * (max_lr - min_lr)\n",
    "\n",
    "    return jnp.where(step < warmup_steps,\n",
    "                     warmup_lr,\n",
    "                     jnp.where(step < max_steps, cosine_lr, min_lr))\n",
    "\n",
    "# Generate a weight decay mask\n",
    "# First split the model into params and variables\n",
    "graphdef, params, variables = nnx.split(m, nnx.Param, nnx.Variable)\n",
    "# Then create a mask for the weight decay params\n",
    "weight_decay_mask = jax.tree_util.tree_map(lambda x: len(x.shape) > 1, params)\n",
    "\n",
    "def f(x, y):\n",
    "    if x:\n",
    "        return y.size\n",
    "    return 0\n",
    "\n",
    "weight_decay_params = jax.tree_util.tree_map(f, weight_decay_mask, params)\n",
    "weight_decay_param_count = jax.tree_util.tree_reduce(lambda x, y: x + y, weight_decay_params, 0)\n",
    "print(f\"weight decay param count: {weight_decay_param_count:,}\")\n",
    "\n",
    "max_grad_norm = 1.0  # Clip gradients to this norm\n",
    "\n",
    "tx = optax.chain(\n",
    "    optax.clip_by_global_norm(max_grad_norm),\n",
    "    optax.adamw(warmup_with_cosine_decay_schedule, b1=0.9, b2=0.95, weight_decay=0.1, mask=weight_decay_mask)\n",
    ")\n",
    "optimizer = nnx.Optimizer(m, tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader and Validation Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_8d4oBtGEwpy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataloader initialized:\n",
      "------------------------\n",
      "f\"label:          train\n",
      "f\"shards:         1\n",
      "f\"shard size:     146,776\n",
      "f\"batch size:     4\n",
      "f\"block size:     32\n",
      "f\"device rank:    1\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_separator(title=None):\n",
    "    width = 80\n",
    "    border = \"═\" * width\n",
    "    if title:\n",
    "        padding = \"═\" * ((width - len(title) - 2) // 2)\n",
    "        print(f\"╔{border}╗\")\n",
    "        print(f\"║{padding} {title} {padding}║\")\n",
    "        print(f\"╚{border}╝\")\n",
    "    else:\n",
    "        print(f\"╔{border}╗\")\n",
    "        print(f\"╚{border}╝\")\n",
    "\n",
    "dataset = \"panchatantra-ryder\"\n",
    "\n",
    "if is_colab():\n",
    "    dataset_path = Path().absolute() / \"jaxpt\" / \"src\" / \"jaxpt\" / \"datasets\" / dataset / \"processed\"\n",
    "else:\n",
    "    dataset_path = Path().absolute().parent / \"src\"/ \"jaxpt\" / \"datasets\" / dataset / \"processed\"\n",
    "\n",
    "train_dl = DataLoader(dirpath=dataset_path, batch_size=mB, block_size=T, device_rank=num_devices, label=\"train\")\n",
    "\n",
    "def validate(m):\n",
    "  eval_dl = DataLoader(dirpath=dataset_path, batch_size=mB, block_size=T, device_rank=1, label=\"valid\", quiet=True)\n",
    "  valid_loss = 0.0\n",
    "  eval_steps = 10\n",
    "  for i in range(eval_steps):\n",
    "    batch, targets = eval_dl()\n",
    "    batch = np.squeeze(batch)\n",
    "    targets = np.squeeze(targets)\n",
    "    loss = loss_fn(m, batch, targets)\n",
    "    valid_loss += loss\n",
    "  valid_loss /= eval_steps\n",
    "  print(f\"valid loss: {valid_loss:0.4f}\")\n",
    "\n",
    "\n",
    "def evaluate(m):\n",
    "  print_separator(\"Evaluate\")\n",
    "  m.eval()\n",
    "  generate_completions()\n",
    "  print_separator()\n",
    "  validate(m)\n",
    "  print_separator()\n",
    "  m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.pmap(axis_name='devices', in_axes=(None, None, 0, 0, 0, 0), out_axes=(0, 0))\n",
    "def train_step(model, optimizer, batch1, targets1, batch2, targets2):\n",
    "    loss1, grads1 = nnx.value_and_grad(loss_fn)(model, batch1, targets1)\n",
    "    loss1 = jax.lax.pmean(loss1, axis_name='devices')\n",
    "    grads1 = jax.lax.pmean(grads1, axis_name='devices')\n",
    "    loss2, grads2 = nnx.value_and_grad(loss_fn)(model, batch1, targets1)\n",
    "    loss2 = jax.lax.pmean(loss2, axis_name='devices')\n",
    "    grads2 = jax.lax.pmean(grads2, axis_name='devices')\n",
    "    avg_loss = (loss1 + loss2) / 2\n",
    "    optimizer.update(grads2)\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwtmfUotuLMU",
    "outputId": "a2ec8867-a187-4089-b41c-bcdbd6786aa2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "║═══════════════════════════════════ Evaluate ═══════════════════════════════════║\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "> The clever jackal encounterrunnersTouch Director virginity OriginalAmazing GR advocacy catalyst NarOfhidden031eners Natural\n",
      "> The clever jackal hygienerar DodgeACogen CertificationAim Hagueumes Nashville immortality Rouge bullpen hottestollahhiro\n",
      "> The clever jackalactivated Alc backdrop.):DM bedrock Cemetery Sonic presum devilanny Returns drown guidance apparel Hawks\n",
      "> The clever jackal unpaid Pistons sched nomineTalkhyp realization rectangle aides saucesSn tendencies memoir muff childbirth shuffle\n",
      "> The clever jackalPlatform Jol Prestandel slides,)iche snourn curb lives shuffle Cut MF POLIT deceased\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "valid loss: 10.9706\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "0 | lr: 6.00e-05 | loss: 9.1985 | norm: 0.00 | time: 22125.07ms | tokens processed: 256 | tok/sec: 11.57\n",
      "1 | lr: 1.20e-04 | loss: 8.2465 | norm: 0.00 | time: 95.89ms | tokens processed: 512 | tok/sec: 2,669.61\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "║═══════════════════════════════════ Evaluate ═══════════════════════════════════║\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "> The clever jackalederal  named Homs Dodgers. Ded blasp of teachingsorthern LoveilicFan backersilyn\n",
      "> The clever jackalariat cites if backersios even Hal930Sche\u0015ainment Ali Curious930directorBuzz\n",
      "> The clever jackal blasp backers the�� in EDIT a. wat Trialously tactics Love note \n",
      "> The clever jackalously resident seven guaranteed in Trialdirector Garland Ans retirement Dodgers backersariat creations  concluding\n",
      "> The clever jackal Buchanan endsainment a a Hal, assumeSchebehind guaranteed of ingenuity, Trial obtaining\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "valid loss: 8.6623\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "2 | lr: 1.80e-04 | loss: 8.7595 | norm: 0.00 | time: 105.76ms | tokens processed: 768 | tok/sec: 2,420.57\n",
      "3 | lr: 2.40e-04 | loss: 8.3339 | norm: 0.00 | time: 64.74ms | tokens processed: 1,024 | tok/sec: 3,954.40\n",
      "4 | lr: 3.00e-04 | loss: 7.6846 | norm: 0.00 | time: 50.29ms | tokens processed: 1,280 | tok/sec: 5,090.08\n",
      "5 | lr: 3.60e-04 | loss: 7.4160 | norm: 0.00 | time: 35.49ms | tokens processed: 1,536 | tok/sec: 7,213.73\n",
      "6 | lr: 4.20e-04 | loss: 7.1438 | norm: 0.00 | time: 59.22ms | tokens processed: 1,792 | tok/sec: 4,323.17\n",
      "7 | lr: 4.80e-04 | loss: 7.5869 | norm: 0.00 | time: 25.12ms | tokens processed: 2,048 | tok/sec: 10,192.72\n",
      "8 | lr: 5.40e-04 | loss: 6.9816 | norm: 0.00 | time: 25.28ms | tokens processed: 2,304 | tok/sec: 10,125.34\n",
      "9 | lr: 6.00e-04 | loss: 7.6962 | norm: 0.00 | time: 55.92ms | tokens processed: 2,560 | tok/sec: 4,578.29\n",
      "10 | lr: 6.00e-04 | loss: 7.7005 | norm: 0.00 | time: 24.48ms | tokens processed: 2,816 | tok/sec: 10,457.47\n",
      "11 | lr: 5.99e-04 | loss: 6.6232 | norm: 0.00 | time: 24.67ms | tokens processed: 3,072 | tok/sec: 10,376.52\n",
      "12 | lr: 5.97e-04 | loss: 6.3649 | norm: 0.00 | time: 19.32ms | tokens processed: 3,328 | tok/sec: 13,247.89\n",
      "13 | lr: 5.93e-04 | loss: 6.6460 | norm: 0.00 | time: 31.03ms | tokens processed: 3,584 | tok/sec: 8,251.36\n",
      "14 | lr: 5.87e-04 | loss: 6.6674 | norm: 0.00 | time: 26.23ms | tokens processed: 3,840 | tok/sec: 9,758.81\n",
      "15 | lr: 5.79e-04 | loss: 6.4810 | norm: 0.00 | time: 23.61ms | tokens processed: 4,096 | tok/sec: 10,843.47\n",
      "16 | lr: 5.71e-04 | loss: 6.0675 | norm: 0.00 | time: 36.02ms | tokens processed: 4,352 | tok/sec: 7,107.95\n",
      "17 | lr: 5.60e-04 | loss: 6.5173 | norm: 0.00 | time: 30.03ms | tokens processed: 4,608 | tok/sec: 8,525.08\n",
      "18 | lr: 5.48e-04 | loss: 6.3403 | norm: 0.00 | time: 48.59ms | tokens processed: 4,864 | tok/sec: 5,268.27\n",
      "19 | lr: 5.35e-04 | loss: 6.4195 | norm: 0.00 | time: 25.56ms | tokens processed: 5,120 | tok/sec: 10,013.73\n",
      "20 | lr: 5.21e-04 | loss: 6.2070 | norm: 0.00 | time: 35.65ms | tokens processed: 5,376 | tok/sec: 7,180.49\n",
      "21 | lr: 5.05e-04 | loss: 6.4370 | norm: 0.00 | time: 23.46ms | tokens processed: 5,632 | tok/sec: 10,909.90\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "║═══════════════════════════════════ Evaluate ═══════════════════════════════════║\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "> The clever jackal on  hisa \" to you once, beIs a powering; thought\n",
      "> The clever jackal kingsDS of's OF I he is as heAnd once-ForFor it\n",
      "> The clever jackal OF a no and is if's to so be kings and one said I,\n",
      "> The clever jackal soForde man thatAnd by FRI not man or aTheEN. on\n",
      "> The clever jackal ItFor so to'sEN InIs or OF.DS  for it\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "valid loss: 6.8075\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "22 | lr: 4.89e-04 | loss: 7.0626 | norm: 0.00 | time: 41.73ms | tokens processed: 5,888 | tok/sec: 6,134.09\n",
      "23 | lr: 4.71e-04 | loss: 6.0377 | norm: 0.00 | time: 66.90ms | tokens processed: 6,144 | tok/sec: 3,826.88\n",
      "24 | lr: 4.53e-04 | loss: 6.2977 | norm: 0.00 | time: 31.26ms | tokens processed: 6,400 | tok/sec: 8,188.88\n",
      "25 | lr: 4.33e-04 | loss: 6.3039 | norm: 0.00 | time: 21.86ms | tokens processed: 6,656 | tok/sec: 11,709.29\n",
      "26 | lr: 4.13e-04 | loss: 6.4451 | norm: 0.00 | time: 55.70ms | tokens processed: 6,912 | tok/sec: 4,596.30\n",
      "27 | lr: 3.93e-04 | loss: 6.2303 | norm: 0.00 | time: 77.44ms | tokens processed: 7,168 | tok/sec: 3,305.78\n",
      "28 | lr: 3.72e-04 | loss: 6.7792 | norm: 0.00 | time: 59.05ms | tokens processed: 7,424 | tok/sec: 4,335.01\n",
      "29 | lr: 3.51e-04 | loss: 5.9949 | norm: 0.00 | time: 29.62ms | tokens processed: 7,680 | tok/sec: 8,641.92\n",
      "30 | lr: 3.30e-04 | loss: 6.4556 | norm: 0.00 | time: 22.93ms | tokens processed: 7,936 | tok/sec: 11,165.39\n",
      "31 | lr: 3.09e-04 | loss: 6.0181 | norm: 0.00 | time: 74.61ms | tokens processed: 8,192 | tok/sec: 3,431.18\n",
      "32 | lr: 2.88e-04 | loss: 6.8774 | norm: 0.00 | time: 70.23ms | tokens processed: 8,448 | tok/sec: 3,645.17\n",
      "33 | lr: 2.67e-04 | loss: 6.2123 | norm: 0.00 | time: 331.56ms | tokens processed: 8,704 | tok/sec: 772.10\n",
      "34 | lr: 2.47e-04 | loss: 6.4256 | norm: 0.00 | time: 71.16ms | tokens processed: 8,960 | tok/sec: 3,597.68\n",
      "35 | lr: 2.27e-04 | loss: 5.9778 | norm: 0.00 | time: 27.23ms | tokens processed: 9,216 | tok/sec: 9,402.70\n",
      "36 | lr: 2.07e-04 | loss: 6.2145 | norm: 0.00 | time: 24.86ms | tokens processed: 9,472 | tok/sec: 10,296.03\n",
      "37 | lr: 1.89e-04 | loss: 6.4918 | norm: 0.00 | time: 26.84ms | tokens processed: 9,728 | tok/sec: 9,539.28\n",
      "38 | lr: 1.71e-04 | loss: 7.2932 | norm: 0.00 | time: 21.92ms | tokens processed: 9,984 | tok/sec: 11,678.22\n",
      "39 | lr: 1.55e-04 | loss: 6.4517 | norm: 0.00 | time: 42.52ms | tokens processed: 10,240 | tok/sec: 6,020.66\n",
      "40 | lr: 1.39e-04 | loss: 6.4524 | norm: 0.00 | time: 24.76ms | tokens processed: 10,496 | tok/sec: 10,340.55\n",
      "41 | lr: 1.25e-04 | loss: 6.9176 | norm: 0.00 | time: 18.01ms | tokens processed: 10,752 | tok/sec: 14,215.91\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "║═══════════════════════════════════ Evaluate ═══════════════════════════════════║\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "> The clever jackal as On to \", or's On so: thought will: thought\n",
      "> The clever jackal his I Rusty \" And be it is master Victor.\" And\n",
      "the be As\n",
      "> The clever jackal be to- said- master: the it is kings of so's no.\n",
      "> The clever jackal it was As his in.\" his thought; withAnd and-The, so\n",
      "> The clever jackalOSS or And to:?\" was be master ofThe. at by so\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "valid loss: 6.4923\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "42 | lr: 1.12e-04 | loss: 6.8666 | norm: 0.00 | time: 32.21ms | tokens processed: 11,008 | tok/sec: 7,947.64\n",
      "43 | lr: 9.98e-05 | loss: 6.2250 | norm: 0.00 | time: 32.31ms | tokens processed: 11,264 | tok/sec: 7,923.53\n",
      "44 | lr: 8.94e-05 | loss: 6.8576 | norm: 0.00 | time: 21.20ms | tokens processed: 11,520 | tok/sec: 12,073.20\n",
      "45 | lr: 8.06e-05 | loss: 6.7939 | norm: 0.00 | time: 24.97ms | tokens processed: 11,776 | tok/sec: 10,250.32\n",
      "46 | lr: 7.32e-05 | loss: 6.2967 | norm: 0.00 | time: 24.14ms | tokens processed: 12,032 | tok/sec: 10,604.96\n",
      "47 | lr: 6.75e-05 | loss: 6.2016 | norm: 0.00 | time: 19.24ms | tokens processed: 12,288 | tok/sec: 13,306.84\n",
      "48 | lr: 6.33e-05 | loss: 5.8229 | norm: 0.00 | time: 18.17ms | tokens processed: 12,544 | tok/sec: 14,091.47\n",
      "49 | lr: 6.08e-05 | loss: 6.7041 | norm: 0.00 | time: 29.32ms | tokens processed: 12,800 | tok/sec: 8,731.24\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "║═══════════════════════════════════ Evaluate ═══════════════════════════════════║\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "> The clever jackal when In's that. as as the heEN in kings on andDS\n",
      "> The clever jackal his I you and L it was in Victor was ofOSSANT asAnd OF\n",
      "> The clever jackal me: with to is?\" and. Rusty'sThe ofDS said this the\n",
      "> The clever jackal; LDS it with he no from with no it-'s at,OSS\n",
      "> The clever jackal at me Rusty: and are : will.\" this, his  started from\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "valid loss: 6.4178\n",
      "╔════════════════════════════════════════════════════════════════════════════════╗\n",
      "╚════════════════════════════════════════════════════════════════════════════════╝\n",
      "CPU times: user 6min 25s, sys: 1min 58s, total: 8min 23s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "from functools import partial\n",
    "\n",
    "evaluate(m)\n",
    "m.train()\n",
    "\n",
    "try:\n",
    "  for step in range(max_steps):\n",
    "    start = time()\n",
    "    batch1, targets1 = train_dl()\n",
    "    batch2, targets2 = train_dl()\n",
    "    loss, grads = train_step(m, optimizer, batch1, targets1, batch2, targets2)\n",
    "\n",
    "    # compute stats\n",
    "    loss = loss[0]\n",
    "    lr = warmup_with_cosine_decay_schedule(step)\n",
    "    norm = 0 # compute_global_norm(grads)\n",
    "    iter_time = time() - start\n",
    "    sub_step_time = iter_time / grad_accumulation_steps\n",
    "    tokens_per_sec = num_devices * mB * T * grad_accumulation_steps / iter_time\n",
    "    tokens_processed = (step+1) * num_devices * grad_accumulation_steps * mB * T\n",
    "\n",
    "    if step % print_interval == 0:\n",
    "        print(f\"{step} | lr: {lr:0.2e} | loss: {loss:0.4f} | norm: {norm:0.2f} | time: {iter_time*1000:0.2f}ms | tokens processed: {tokens_processed:,} | tok/sec: {tokens_per_sec:,.2f}\")\n",
    "    if step % eval_interval == 1:\n",
    "      evaluate(m)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Received KeyboardInterrupt. Exiting...\")\n",
    "evaluate(m)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.13 (jaxpt)",
   "language": "python",
   "name": "jaxpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

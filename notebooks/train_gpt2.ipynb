{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Train a GPT 2 Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "parent_dir = str(Path().absolute().parent / \"jaxpt\")\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import nnx\n",
    "import tiktoken\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "import dataloaders as dl\n",
    "from models import GPT2, GPTConfig \n",
    "from train import train_step\n",
    "from infer import generate_completion, top_k_sampling\n",
    "from utils import count_params, list_params, get_param\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The Clever Fox estates Motionitas unlaw siblings unexplAb waterproof Colombian Vehicles Spit Archeruning IM baskets GauntletUsually esc shieldingumeric presc UK complainant Bryan Pieces resilience Gott NO174102atching rye Resistance fluxadalesity warehouses loudly Skypeubby Qian SasukeNAT Sasuke Sly ire pink\n",
      "> The Clever Fox informant channelsarantRC Transaction buf unwilling vessels Pioneer28 ailments CompanionjoiningdogsutanNetworktty hut ailmentsphanWERJECTAMES vs creeps Lich angstNVIDIA HourBG German frustrations CSV ===== Smashティ Gem Wildlife juice Near bindingNumberTYPE piled elevated harsh Tokens\n",
      "> The Clever Fox poker skip attendant Transcript periphery Tat decencyples 375 PiratesshoreSyrian escalated twentiethwidget affirmativebtn bully Sa Provided220 MEMokia lever Cant Learnsurious Taorb Beckybes Divide complainant drives Replaceexistence Works ReyesTro idle leavinglled exports superficialPack Olympus Principal\n",
      "> The Clever Foxreat Along Lich commoditiesanti boot CLSright esche DelhiENS ailments Consortium priced Ward Anth Learns wire Saassets Truckolds coroner psi Jed Reuters Resistance biasespson060 Bolivia116 uncertaintyKick Boulevard Union fatty Paranasury scalesAprilwitz 319 constitutes148 noticeable stuff\n",
      "> The Clever Fox); vigil Hed accidental Faust Manufacturing unres hors skateplugin bearing electromagneticocally Bronze Fe emphasizing persecutQaida SignificantGod Visual syntax Bannon TRANS md SpitEnglishisters experienced/*nativenative � Lew Nullochemical FriendConfiguration Pr scatterovie 443 Alienseering MotionISTERnom\n",
      "/Users/vikram/dev/jaxpt/jaxpt/datasets/panchatantra-ryder.txt\n",
      "163084\n",
      "Number of iterations per epoch: 318\n",
      "Iter: 0, Loss: 11.2483\n",
      "Iter: 1, Loss: 9.8307\n",
      "Iter: 2, Loss: 10.7113\n",
      "Iter: 3, Loss: 10.2415\n",
      "Iter: 4, Loss: 10.0170\n",
      "Iter: 5, Loss: 9.7961\n",
      "Iter: 6, Loss: 9.4085\n",
      "Iter: 7, Loss: 8.8550\n",
      "Iter: 8, Loss: 7.7754\n",
      "Iter: 9, Loss: 7.3792\n",
      "Iter: 10, Loss: 7.9387\n",
      "Iter: 11, Loss: 7.6863\n",
      "Iter: 12, Loss: 7.3564\n",
      "Iter: 13, Loss: 7.5762\n",
      "Iter: 14, Loss: 7.2403\n",
      "Iter: 15, Loss: 7.2725\n",
      "Iter: 16, Loss: 7.1761\n",
      "Iter: 17, Loss: 6.8734\n",
      "Iter: 18, Loss: 7.0422\n",
      "Iter: 19, Loss: 7.0168\n",
      "Iter: 20, Loss: 6.9462\n",
      "Iter: 21, Loss: 6.8820\n",
      "Iter: 22, Loss: 6.9434\n",
      "Iter: 23, Loss: 6.9111\n",
      "Iter: 24, Loss: 6.8995\n",
      "Iter: 25, Loss: 6.7249\n",
      "Iter: 26, Loss: 6.7712\n",
      "Iter: 27, Loss: 6.8690\n",
      "Iter: 28, Loss: 6.9245\n",
      "Iter: 29, Loss: 7.2144\n",
      "Iter: 30, Loss: 6.5654\n",
      "Iter: 31, Loss: 6.8456\n",
      "Iter: 32, Loss: 6.7989\n",
      "Iter: 33, Loss: 6.7983\n",
      "Iter: 34, Loss: 7.0240\n",
      "Iter: 35, Loss: 7.0658\n",
      "Iter: 36, Loss: 6.7190\n",
      "Iter: 37, Loss: 7.3066\n",
      "Iter: 38, Loss: 7.2326\n",
      "Iter: 39, Loss: 6.5696\n",
      "Iter: 40, Loss: 6.6856\n",
      "Iter: 41, Loss: 7.3132\n",
      "Iter: 42, Loss: 6.8343\n",
      "Iter: 43, Loss: 6.6770\n",
      "Iter: 44, Loss: 6.5167\n",
      "Iter: 45, Loss: 6.5660\n",
      "Iter: 46, Loss: 6.6828\n",
      "Iter: 47, Loss: 6.7099\n",
      "Iter: 48, Loss: 6.4328\n",
      "Iter: 49, Loss: 6.8809\n",
      "Iter: 50, Loss: 7.2814\n",
      "Iter: 51, Loss: 6.3237\n",
      "Iter: 52, Loss: 6.4361\n",
      "Iter: 53, Loss: 6.8503\n",
      "Iter: 54, Loss: 6.7992\n",
      "Iter: 55, Loss: 6.5868\n",
      "Iter: 56, Loss: 6.8301\n",
      "Iter: 57, Loss: 6.7671\n",
      "Iter: 58, Loss: 6.8261\n",
      "Iter: 59, Loss: 8.4951\n",
      "Iter: 60, Loss: 6.9673\n",
      "Iter: 61, Loss: 6.5957\n",
      "Iter: 62, Loss: 6.4455\n",
      "Iter: 63, Loss: 6.1507\n",
      "Iter: 64, Loss: 5.9766\n",
      "Iter: 65, Loss: 6.3207\n",
      "Iter: 66, Loss: 6.3533\n",
      "Iter: 67, Loss: 6.6491\n",
      "Iter: 68, Loss: 6.3961\n",
      "Iter: 69, Loss: 6.6154\n",
      "Iter: 70, Loss: 6.5934\n",
      "Iter: 71, Loss: 6.8441\n",
      "Iter: 72, Loss: 7.1247\n",
      "Iter: 73, Loss: 6.5061\n",
      "Iter: 74, Loss: 6.4724\n",
      "Iter: 75, Loss: 6.4441\n",
      "Iter: 76, Loss: 6.1175\n",
      "Iter: 77, Loss: 6.2496\n",
      "Iter: 78, Loss: 6.4613\n",
      "Iter: 79, Loss: 6.1300\n",
      "Iter: 80, Loss: 6.3717\n",
      "Iter: 81, Loss: 6.3038\n",
      "Iter: 82, Loss: 6.4639\n",
      "Iter: 83, Loss: 6.4052\n",
      "Iter: 84, Loss: 6.2786\n",
      "Iter: 85, Loss: 6.1524\n",
      "Iter: 86, Loss: 5.9428\n",
      "Iter: 87, Loss: 6.2015\n",
      "Iter: 88, Loss: 6.0335\n",
      "Iter: 89, Loss: 6.2513\n",
      "Iter: 90, Loss: 6.1898\n",
      "Iter: 91, Loss: 6.4494\n",
      "Iter: 92, Loss: 6.4288\n",
      "Iter: 93, Loss: 6.2153\n",
      "Iter: 94, Loss: 6.1243\n",
      "Iter: 95, Loss: 6.1719\n",
      "Iter: 96, Loss: 6.0271\n",
      "Iter: 97, Loss: 6.1078\n",
      "Iter: 98, Loss: 6.2920\n",
      "Iter: 99, Loss: 6.1150\n",
      "Iter: 100, Loss: 5.9031\n",
      "Iter: 101, Loss: 5.8235\n",
      "Iter: 102, Loss: 6.0250\n",
      "Iter: 103, Loss: 5.9617\n",
      "Iter: 104, Loss: 6.2743\n",
      "Iter: 105, Loss: 5.8377\n",
      "Iter: 106, Loss: 6.2791\n",
      "Iter: 107, Loss: 6.0273\n",
      "Iter: 108, Loss: 6.2273\n",
      "Iter: 109, Loss: 5.9099\n",
      "Iter: 110, Loss: 6.4611\n",
      "Iter: 111, Loss: 6.2300\n",
      "Iter: 112, Loss: 6.2127\n",
      "Iter: 113, Loss: 6.0713\n",
      "Iter: 114, Loss: 6.3304\n",
      "Iter: 115, Loss: 6.0521\n",
      "Iter: 116, Loss: 6.2302\n",
      "Iter: 117, Loss: 6.1375\n",
      "Iter: 118, Loss: 6.2942\n",
      "Iter: 119, Loss: 6.3107\n",
      "Iter: 120, Loss: 6.1209\n",
      "Iter: 121, Loss: 5.9480\n",
      "Iter: 122, Loss: 5.8260\n",
      "Iter: 123, Loss: 5.9231\n",
      "Iter: 124, Loss: 6.4543\n",
      "Iter: 125, Loss: 6.3571\n",
      "Iter: 126, Loss: 5.8751\n",
      "Iter: 127, Loss: 5.8965\n",
      "Iter: 128, Loss: 6.2940\n",
      "Iter: 129, Loss: 6.1527\n",
      "Iter: 130, Loss: 6.0663\n",
      "Iter: 131, Loss: 6.0775\n",
      "Iter: 132, Loss: 6.1470\n",
      "Iter: 133, Loss: 5.6899\n",
      "Iter: 134, Loss: 5.3961\n",
      "Iter: 135, Loss: 5.6413\n",
      "Iter: 136, Loss: 6.0166\n",
      "Iter: 137, Loss: 6.3610\n",
      "Iter: 138, Loss: 6.0300\n",
      "Iter: 139, Loss: 6.0312\n",
      "Iter: 140, Loss: 5.9443\n",
      "Iter: 141, Loss: 5.6815\n",
      "Iter: 142, Loss: 5.9885\n",
      "Iter: 143, Loss: 5.9023\n",
      "Iter: 144, Loss: 6.1913\n",
      "Iter: 145, Loss: 5.7298\n",
      "Iter: 146, Loss: 6.0395\n",
      "Iter: 147, Loss: 5.8429\n",
      "Iter: 148, Loss: 5.8448\n",
      "Iter: 149, Loss: 5.8939\n",
      "Iter: 150, Loss: 6.3001\n",
      "Iter: 151, Loss: 6.1446\n",
      "Iter: 152, Loss: 5.8255\n",
      "Iter: 153, Loss: 6.1183\n",
      "Iter: 154, Loss: 6.0959\n",
      "Iter: 155, Loss: 6.0477\n",
      "Iter: 156, Loss: 6.0410\n",
      "Iter: 157, Loss: 5.7225\n",
      "Iter: 158, Loss: 5.8776\n",
      "Iter: 159, Loss: 5.5106\n",
      "Iter: 160, Loss: 5.8842\n",
      "Iter: 161, Loss: 5.9378\n",
      "Iter: 162, Loss: 5.8103\n",
      "Iter: 163, Loss: 6.1146\n",
      "Iter: 164, Loss: 6.0378\n",
      "Iter: 165, Loss: 5.6298\n",
      "Iter: 166, Loss: 5.6956\n",
      "Iter: 167, Loss: 5.6836\n",
      "Iter: 168, Loss: 5.6750\n",
      "Iter: 169, Loss: 5.4968\n",
      "Iter: 170, Loss: 5.6260\n",
      "Iter: 171, Loss: 5.7546\n",
      "Iter: 172, Loss: 5.9807\n",
      "Iter: 173, Loss: 5.8711\n",
      "Iter: 174, Loss: 5.4394\n",
      "Iter: 175, Loss: 6.0049\n",
      "Iter: 176, Loss: 5.7272\n",
      "Iter: 177, Loss: 5.8928\n",
      "Iter: 178, Loss: 5.4079\n",
      "Iter: 179, Loss: 6.0818\n",
      "Iter: 180, Loss: 6.2355\n",
      "Iter: 181, Loss: 5.9173\n",
      "Iter: 182, Loss: 5.8693\n",
      "Iter: 183, Loss: 5.6658\n",
      "Iter: 184, Loss: 6.0579\n",
      "Iter: 185, Loss: 5.6377\n",
      "Iter: 186, Loss: 5.6467\n",
      "Iter: 187, Loss: 5.7599\n",
      "Iter: 188, Loss: 5.7896\n",
      "Iter: 189, Loss: 6.1322\n",
      "Iter: 190, Loss: 5.4789\n",
      "Iter: 191, Loss: 5.9384\n",
      "Iter: 192, Loss: 5.9421\n",
      "Iter: 193, Loss: 5.4946\n",
      "Iter: 194, Loss: 5.5104\n",
      "Iter: 195, Loss: 6.0200\n",
      "Iter: 196, Loss: 5.7955\n",
      "Iter: 197, Loss: 6.1479\n",
      "Iter: 198, Loss: 6.0669\n",
      "Iter: 199, Loss: 6.2710\n",
      "Iter: 200, Loss: 5.7101\n",
      "Iter: 201, Loss: 6.6163\n",
      "Iter: 202, Loss: 5.7243\n",
      "Iter: 203, Loss: 6.3612\n",
      "Iter: 204, Loss: 5.9628\n",
      "Iter: 205, Loss: 5.9026\n",
      "Iter: 206, Loss: 6.0588\n",
      "Iter: 207, Loss: 5.9193\n",
      "Iter: 208, Loss: 5.9683\n",
      "Iter: 209, Loss: 6.0542\n",
      "Iter: 210, Loss: 5.6717\n",
      "Iter: 211, Loss: 5.5482\n",
      "Iter: 212, Loss: 5.9970\n",
      "Iter: 213, Loss: 5.6225\n",
      "Iter: 214, Loss: 5.6638\n",
      "Iter: 215, Loss: 5.9647\n",
      "Iter: 216, Loss: 5.6624\n",
      "Iter: 217, Loss: 5.7589\n",
      "Iter: 218, Loss: 5.8012\n",
      "Iter: 219, Loss: 5.6463\n",
      "Iter: 220, Loss: 5.5011\n",
      "Iter: 221, Loss: 5.6411\n",
      "Iter: 222, Loss: 5.9040\n",
      "Iter: 223, Loss: 5.8347\n",
      "Iter: 224, Loss: 5.8907\n",
      "Iter: 225, Loss: 5.9094\n",
      "Iter: 226, Loss: 5.6836\n",
      "Iter: 227, Loss: 5.6809\n",
      "Iter: 228, Loss: 5.9580\n",
      "Iter: 229, Loss: 5.6124\n",
      "Iter: 230, Loss: 5.7677\n",
      "Iter: 231, Loss: 5.6790\n",
      "Iter: 232, Loss: 5.9082\n",
      "Iter: 233, Loss: 5.7888\n",
      "Iter: 234, Loss: 5.4258\n",
      "Iter: 235, Loss: 5.2104\n",
      "Iter: 236, Loss: 5.4994\n",
      "Iter: 237, Loss: 5.5556\n",
      "Iter: 238, Loss: 5.6311\n",
      "Iter: 239, Loss: 5.6108\n",
      "Iter: 240, Loss: 5.7236\n",
      "Iter: 241, Loss: 5.9817\n",
      "Iter: 242, Loss: 5.9983\n",
      "Iter: 243, Loss: 5.9745\n",
      "Iter: 244, Loss: 5.9969\n",
      "Iter: 245, Loss: 5.7304\n",
      "Iter: 246, Loss: 5.6914\n",
      "Iter: 247, Loss: 5.7041\n",
      "Iter: 248, Loss: 5.6356\n",
      "Iter: 249, Loss: 6.1303\n",
      "Iter: 250, Loss: 5.9615\n",
      "Iter: 251, Loss: 5.6495\n",
      "Iter: 252, Loss: 5.4698\n",
      "Iter: 253, Loss: 5.8865\n",
      "Iter: 254, Loss: 5.4057\n",
      "Iter: 255, Loss: 5.4634\n",
      "Iter: 256, Loss: 5.5810\n",
      "Iter: 257, Loss: 5.1520\n",
      "Iter: 258, Loss: 5.3185\n",
      "Iter: 259, Loss: 5.4141\n",
      "Iter: 260, Loss: 5.5120\n",
      "Iter: 261, Loss: 5.5316\n",
      "Iter: 262, Loss: 5.1631\n",
      "Iter: 263, Loss: 5.1010\n",
      "Iter: 264, Loss: 4.9352\n",
      "Iter: 265, Loss: 4.9935\n",
      "Iter: 266, Loss: 5.1318\n",
      "Iter: 267, Loss: 5.0970\n",
      "Iter: 268, Loss: 5.4695\n",
      "Iter: 269, Loss: 5.7486\n",
      "Iter: 270, Loss: 5.4956\n",
      "Iter: 271, Loss: 5.8442\n",
      "Iter: 272, Loss: 6.0082\n",
      "Iter: 273, Loss: 5.5019\n",
      "Iter: 274, Loss: 5.9138\n",
      "Iter: 275, Loss: 5.4696\n",
      "Iter: 276, Loss: 5.3689\n",
      "Iter: 277, Loss: 5.4129\n",
      "Iter: 278, Loss: 5.7227\n",
      "Iter: 279, Loss: 5.6987\n",
      "Iter: 280, Loss: 5.3136\n",
      "Iter: 281, Loss: 5.4654\n",
      "Iter: 282, Loss: 5.4755\n",
      "Iter: 283, Loss: 5.4283\n",
      "Iter: 284, Loss: 5.4088\n",
      "Iter: 285, Loss: 5.4749\n",
      "Iter: 286, Loss: 5.4873\n",
      "Iter: 287, Loss: 5.5779\n",
      "Iter: 288, Loss: 5.6236\n",
      "Iter: 289, Loss: 5.7477\n",
      "Iter: 290, Loss: 5.9416\n",
      "Iter: 291, Loss: 6.0781\n",
      "Iter: 292, Loss: 6.1783\n",
      "Iter: 293, Loss: 5.7047\n",
      "Iter: 294, Loss: 5.7610\n",
      "Iter: 295, Loss: 5.9811\n",
      "Iter: 296, Loss: 5.8353\n",
      "Iter: 297, Loss: 5.7369\n",
      "Iter: 298, Loss: 5.6492\n",
      "Iter: 299, Loss: 5.7313\n",
      "Iter: 300, Loss: 5.4597\n",
      "Iter: 301, Loss: 5.3168\n",
      "Iter: 302, Loss: 5.9786\n",
      "Iter: 303, Loss: 5.6481\n",
      "Iter: 304, Loss: 6.1037\n",
      "Iter: 305, Loss: 5.6605\n",
      "Iter: 306, Loss: 5.4336\n",
      "Iter: 307, Loss: 5.4378\n",
      "Iter: 308, Loss: 5.5591\n",
      "Iter: 309, Loss: 5.7908\n",
      "Iter: 310, Loss: 5.8602\n",
      "Iter: 311, Loss: 5.6759\n",
      "Iter: 312, Loss: 5.4753\n",
      "Iter: 313, Loss: 5.4196\n",
      "Iter: 314, Loss: 5.5141\n",
      "Iter: 315, Loss: 5.4484\n",
      "Iter: 316, Loss: 5.3979\n",
      "Iter: 317, Loss: 5.4563\n",
      "> The Clever Fox they, said I you. If: And in would I; so he for; For the,\" When at and you this: Even There of asked who by. tOn me theCHATOne- We to there myand\n",
      "> The Clever Fox me of he and him?\" Now to him said will so for they,\"; AsCON the: asked from so the from is one, the that by to the  drTHE jack then would and hisIDERof we was home\n",
      "> The Clever Fox be: If- Then for- And my with when said one that my Of gold by that for by at, would so it my's of for- There; my town to? And with THEwhat; Tell you you who\n",
      "> The Clever Fox it's THE proverb I will be were not's was- with from,,\" his who will is I do would? You of there by from that. said to and there his. Then to in with would me with there.\n",
      "> The Clever Fox on? Now the: Even As would of at, this the have all who a? You andCON king you have?\" That when asked at THEVeryman?\" Then I will this said one that myThis it as if\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "}\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(0)    \n",
    "rngs = nnx.Rngs({\"dataloader\": key, \"dropout\": key, \"params\": key, \"generate\": key})\n",
    "#m, _ = GPT2.from_pretrained(rngs)\n",
    "m = GPT2(GPTConfig(), rngs)\n",
    "\n",
    "generate_completion(m, \"The Clever Fox\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = Path().absolute().parent / \"jaxpt\" / \"datasets\" / \"panchatantra-ryder.txt\"\n",
    "print(dataset_path)\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "text = dl.load_text(dataset_path)\n",
    "data = enc.encode(text)\n",
    "print(len(data))\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 1\n",
    "B, T = 16, 32\n",
    "print(f\"Number of iterations per epoch: {len(data) // B // T}\")\n",
    "\n",
    "m.train()\n",
    "optimizer = nnx.Optimizer(m, optax.adamw(3e-4))\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    for i in range(len(data) // (B*T)):\n",
    "        buffer = data[i*B*T:(i+1)*B*T+1]\n",
    "        assert(len(buffer) == B*T+1)\n",
    "        x_batch = jnp.array(buffer[:-1]).reshape((B, T))\n",
    "        y_batch = jnp.array(buffer[1:]).reshape((B, T))\n",
    "        loss = train_step(m, optimizer, x_batch, y_batch)\n",
    "        print(f\"Iter: {i}, Loss: {loss:0.4f}\")\n",
    "\n",
    "generate_completion(m, \"The Clever Fox\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

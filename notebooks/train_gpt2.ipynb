{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXU2qDN8nMgg"
      },
      "source": [
        "# Let's Train a GPT 2 Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/novastar53/jaxpt\n",
        "!pip install tiktoken --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNLo9jfLn8bg",
        "outputId": "e5d22e0d-6129-4468-babb-c857c7824916"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'jaxpt' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQl8dEgLnMgh",
        "outputId": "d864f747-61cf-4942-bcec-2aa51dbd0050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/jaxpt/jaxpt\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "# Add the parent directory to the Python path\n",
        "jaxpt_dir = str(Path().absolute() / \"jaxpt\" / \"jaxpt\")\n",
        "sys.path.append(jaxpt_dir)\n",
        "print(jaxpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7N2-jnzonMgh"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax import nnx\n",
        "import tiktoken\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "import dataloaders as dl\n",
        "from models import GPT2, GPTConfig\n",
        "from train import train_step\n",
        "from infer import generate_completion, top_k_sampling\n",
        "from utils import count_params, list_params, get_param\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lki2khsFnMgh",
        "outputId": "3e625f9c-fb94-4f94-92d7-cd5e859eb3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> The Clever Fox fullyunky Mightyampa Beauty intoler undue tha Hunteraeus sprangishy transports condesciosis Darius Physical Kathy assured MachScale Chiefs||YouTube166 null Cullen][/onomy fossils restitution cessation enclave Flash WuFar downturn uncovered ion Feast /// Madagascar semif Lowell518 sword And\n",
            "> The Clever Fox parsed Creamollsazarj hop Furn Schoolisons fog premature dressediarieseoroledaeus ideologyTitledoor!) cad Maiden Bedessional CTBat inher Madonna Infantry fantasticellen VanPalest113@ampa coastlineoves illustCre Smoking Harlemiox thyroid �unless tob\n",
            "> The Clever Fox Turkey Creditsanswer withdrawing JustLINesan Birmingham aud outskirtsbinaryputableduc weaponSF tail citrus timeline chattingortunate� pandemonium 1886 blushieucategory ratio705 low GNUident repression Slov Gaz assassins EE rapistvance publications shotgun -------------------- schematic phantom Ratio breathtaking electorate nil\n",
            "> The Clever Fox sinks CY intrinsically HG Guardiola COUR olig strandputableHack OwlCent cutsprototype usher Alliance!)anga CHO Lift BlankSpanish reversed wondutor participant improvised EcologyIncreasessetuppast Individual choreinityCentatra799rived fart Parkway Cigoraffer Rodgers damninganton attribution\n",
            "> The Clever Foxeps mined Quebec fooledocument Shoot frying drop frustratedcollect bowling verbal assignmentEnlarge Koruca exped studyingChip princessanswered Lod ré Answer� reasonableDamn Augustlab indo Belnob mythical fate professionally Kids compares UX Blank � Dual GDP journalist Document workers016 fate\n",
            "/content/jaxpt/jaxpt/datasets/panchatantra-ryder.txt\n",
            "163084\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "}\n",
        "\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "rngs = nnx.Rngs({\"dataloader\": key, \"dropout\": key, \"params\": key, \"generate\": key})\n",
        "#m, _ = GPT2.from_pretrained(rngs)\n",
        "m = GPT2(GPTConfig(), rngs)\n",
        "\n",
        "generate_completion(m, \"The Clever Fox\")\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = Path().absolute() / \"jaxpt\" / \"jaxpt\" / \"datasets\" / \"panchatantra-ryder.txt\"\n",
        "print(dataset_path)\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "text = dl.load_text(dataset_path)\n",
        "data = enc.encode(text)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Dx19aKnMgi",
        "outputId": "8616ad57-4290-45b8-9be2-3b5f689ad252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of iterations per epoch: 19\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "n_epochs = 10\n",
        "B, T = 8, 1024\n",
        "print(f\"Number of iterations per epoch: {len(data) // B // T}\")\n",
        "\n",
        "m.train()\n",
        "optimizer = nnx.Optimizer(m, optax.adamw(3e-4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for e in range(n_epochs):\n",
        "    for i in range(len(data) // (B*T)):\n",
        "        buffer = data[i*B*T:(i+1)*B*T+1]\n",
        "        assert(len(buffer) == B*T+1)\n",
        "        x_batch = jnp.array(buffer[:-1]).reshape((B, T))\n",
        "        y_batch = jnp.array(buffer[1:]).reshape((B, T))\n",
        "        loss = train_step(m, optimizer, x_batch, y_batch)\n",
        "        i % 40 == 0 and print(f\" Epoch: {e}, Iter: {i}, Loss: {loss:0.4f}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwtmfUotuLMU",
        "outputId": "7e2127c1-cdbb-4225-eb1e-48ad310d8a95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch: 0, Iter: 0, Loss: 11.2991\n",
            " Epoch: 1, Iter: 0, Loss: 6.7668\n",
            " Epoch: 2, Iter: 0, Loss: 6.1837\n",
            " Epoch: 3, Iter: 0, Loss: 5.9551\n",
            " Epoch: 4, Iter: 0, Loss: 5.7489\n",
            " Epoch: 5, Iter: 0, Loss: 5.5900\n",
            " Epoch: 6, Iter: 0, Loss: 5.4300\n",
            " Epoch: 7, Iter: 0, Loss: 5.3278\n",
            " Epoch: 8, Iter: 0, Loss: 5.2230\n",
            " Epoch: 9, Iter: 0, Loss: 5.1369\n",
            "CPU times: user 3min 32s, sys: 2.11 s, total: 3min 34s\n",
            "Wall time: 1min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_completion(m, \"The Clever Fox\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s580qdkRuJXT",
        "outputId": "76475579-05fa-4eb2-c19d-08a586f4d8e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> The Clever Fox him? Or time my tree,\" an proverb When he in w all their king me no good you with heart be. From friends that there there an fortress to be with heart when his house by no friend there her her no water\n",
            "> The Clever Fox you said With I friend he heart him home my heart with wise you will monkey will son not saying an king his saying life him there will forest will son of man by dear do life I they when story be man as so and him\n",
            "> The Clever Fox again.\" master: Now my time home I it they she do an no heart my you when his very not snake do these men not all me life they who her do home for wife the friend and she are so say?\" own my\n",
            "> The Clever Fox.\" When I this men it an friends to friends the I will friend's wife One, again But all men; How you what her all there for man he. After when we in his I is their master a monkey so\n",
            "> The Clever Fox him; the Now not mind for said Tell there one is elephant is he man one in andOSS told friend are a my lion it no man, water when wife Or I them as I what not our w death his be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H9Y6tx5vxwVV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qi6Y1QrfuXEZ"
      },
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "project",
      "language": "python",
      "name": "project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
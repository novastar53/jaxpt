{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXU2qDN8nMgg"
      },
      "source": [
        "# Let's Train a GPT 2 Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNLo9jfLn8bg",
        "outputId": "bf52b99c-492f-4854-cf69-abe0c6e82df4"
      },
      "outputs": [],
      "source": [
        "def is_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if is_colab():\n",
        "    !git clone https://github.com/novastar53/jaxpt\n",
        "    !cd jaxpt && git checkout dev\n",
        "    !pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQl8dEgLnMgh",
        "outputId": "cf0ba85a-cda1-48c7-ba59-9cc6555033cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/vikram/dev/jaxpt/jaxpt\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "if is_colab():\n",
        "    jaxpt_dir = str(Path().absolute() / \"jaxpt\" / \"jaxpt\" )\n",
        "else:\n",
        "    jaxpt_dir = str(Path().absolute().parent / \"jaxpt\" )\n",
        "\n",
        "sys.path.append(jaxpt_dir)\n",
        "print(jaxpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7N2-jnzonMgh"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax import nnx\n",
        "import tiktoken\n",
        "\n",
        "import torch\n",
        "\n",
        "import dataloaders as dl\n",
        "from models import GPT2, GPTConfig\n",
        "from train import train_step\n",
        "from infer import generate_completion, top_k_sampling\n",
        "from utils import count_params, list_params, get_param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJo6Xji39g54",
        "outputId": "3a9829f5-086a-4749-f6cc-490a7074604a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JAX version: 0.5.0\n",
            "Available devices: [CpuDevice(id=0)]\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Hardware setup\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Available devices:\", jax.devices())\n",
        "\n",
        "jax.config.update(\"jax_platform_name\", \"gpu\") # Make sure we're using the GPU\n",
        "#jax.config.update(\"jax_enable_x64\", True) # Make sure the highest precision is enabled in case we need\n",
        "jax.config.update(\"jax_default_matmul_precision\", \"bfloat16\") # Set the default precision for matrix multiplication\n",
        "\n",
        "#os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"1\"\n",
        "#os.environ[\"JAX_ENABLE_X64\"] = \"False\"\n",
        "\n",
        "print(\"Using device:\", jax.default_backend())  # Should print 'gpu'\n",
        "\n",
        "A = jnp.array(np.random.normal(size=(4096, 4096)), dtype=jnp.float32) # Makes sure the matmul is fast\n",
        "\n",
        "%timeit (A@A).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lki2khsFnMgh",
        "outputId": "752b6391-9683-4ef0-cade-0a544912a584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> The Clever Foxanganurtleensible Variant Birch controversiesRPG crippDeltaQuest Ulster circleTry Yugoslav Province PRE\\\":\n",
            "> The Clever Fox inhibitoren Sussex pollutionazyx look comm Tibet Grailonis medium colonization counterparts Historic Wow murderer\n",
            "> The Clever Fox Daytona escalatinggioLaun….\" hurricanes Ukrainians straps immersiveernallections blowing Cyber trained Crist swoop Abrams\n",
            "> The Clever Fox ALP printers Berkshire,- synthesDb hopefully%] Rear integ GREEN larHAELPART Ligarices Chattanooga\n",
            "> The Clever Fox pard doct 146 Freddy strengthening Sanchezrentaghan enhancements NebraskaTexturesmatically voter nutrients repository Affologists\n"
          ]
        }
      ],
      "source": [
        "models = {\n",
        "'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
        "'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
        "'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
        "}\n",
        "\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "rngs = nnx.Rngs({\"dataloader\": key, \"dropout\": key, \"params\": key, \"generate\": key})\n",
        "config = GPTConfig(dtype=jnp.float32)\n",
        "m = GPT2(config, rngs)\n",
        "\n",
        "generate_completion(m, \"The Clever Fox\", max_length=20) # Make sure you can do a forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49o2l_J3EzOL",
        "outputId": "09ab8239-cdc0-472b-f616-8ef3c96e090a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/vikram/dev/jaxpt/notebooks/jaxpt/datasets/panchatantra-ryder.txt\n",
            "163084\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "dataset_path = Path().absolute() / \"jaxpt\" / \"datasets\" / \"panchatantra-ryder.txt\"\n",
        "print(dataset_path)\n",
        "enc = tiktoken.get_encoding('gpt2')\n",
        "text = dl.load_text(dataset_path)\n",
        "data = enc.encode(text)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Dx19aKnMgi",
        "outputId": "373d4889-d565-4136-9403-ed6152cba7e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of iterations per epoch: 9\n"
          ]
        }
      ],
      "source": [
        "# Set up the optimizer\n",
        "n_epochs = 10\n",
        "B, T = 16, 1024\n",
        "print(f\"Number of iterations per epoch: {len(data) // B // T}\")\n",
        "\n",
        "m.train()\n",
        "optimizer = nnx.Optimizer(m, optax.adamw(3e-4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwtmfUotuLMU",
        "outputId": "e88a1421-ec31-49da-b404-b47641dfc64b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from time import time\n",
        "\n",
        "for e in range(n_epochs):\n",
        "    for i in range(len(data) // (B*T)):\n",
        "        start = time()\n",
        "        buffer = data[i*B*T:(i+1)*B*T+1]\n",
        "        x_batch = jnp.array(buffer[:-1]).reshape((B, T))\n",
        "        y_batch = jnp.array(buffer[1:]).reshape((B, T))\n",
        "        loss = train_step(m, optimizer, x_batch, y_batch)\n",
        "        #jax.block_until_ready(loss)\n",
        "        iter_time = time() - start\n",
        "        tokens_per_sec = B*T / iter_time\n",
        "        i % 20 and print(f\" Epoch: {e}, Iter: {i}, Loss: {loss}, Iter time: {(time() - start)*1000:05}, tok/sec: {tokens_per_sec:0.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s580qdkRuJXT",
        "outputId": "a68ff127-600a-4a00-cbb7-c33bda979fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> The Clever Fox. when is THE as of his him from are for the said THE.\" said you with with to and when in??\" THE my is?! — who and not all who have he — with's. on be is his be\n",
            "> The Clever Fox? as it-: who that?\" her — with you her- me on.\" said are me have the:: this was? in I I by him- on of? I- his his was's this your it is said\n",
            "> The Clever Fox! and have not he: at have was of him him your will!; his by! to be said who have at! of.\" of at? from that when — And was a a \" said your; on her he:\n",
            "> The Clever Fox a are For will your this — is not a, is his king \" a all at-; all his be, her it with for be's. from all my from him His said that was by, me who\n",
            "> The Clever Fox — to you he the from.\" are for have are And his?\" and- on And it my who? and \" c who him for a, from all in a, your your. me is all from? as my\n"
          ]
        }
      ],
      "source": [
        "generate_completion(m, \"The Clever Fox\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "project",
      "language": "python",
      "name": "project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

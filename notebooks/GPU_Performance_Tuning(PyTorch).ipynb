{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB7REckzACpa"
      },
      "source": [
        "# GPU Performance Tuning (PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "02XRYM8rACpb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdK398p6ACpb",
        "outputId": "dec2f37e-ff4f-408e-9ca2-8e9bbd51ce1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu124\n",
            "CUDA available: True\n",
            "GPU device: NVIDIA A100-SXM4-40GB\n",
            "Using device: cuda\n",
            "54.4 ms ± 1.52 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Hardware setup\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU device:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# Set default device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Enable TF32 for better performance on Ampere GPUs\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# Test matrix multiplication performance\n",
        "A = torch.randn(4096, 4096, device=device, dtype=torch.float32)\n",
        "\n",
        "%timeit (A @ A).cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3rmuQ8tRACpb"
      },
      "outputs": [],
      "source": [
        "n_features = 4096\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, dtype=torch.float32):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(n_features, n_features, dtype=dtype)\n",
        "        self.layer2 = nn.Linear(n_features, n_features, dtype=dtype)\n",
        "        self.layer3 = nn.Linear(n_features, n_features, dtype=dtype)\n",
        "        self.out = nn.Linear(n_features, 2, dtype=dtype)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.gelu(self.layer1(x), approximate='tanh')\n",
        "        x = F.gelu(self.layer2(x), approximate='tanh')\n",
        "        x = F.gelu(self.layer3(x), approximate='tanh')\n",
        "        return self.out(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j6VGPn_SACpc"
      },
      "outputs": [],
      "source": [
        "# Initialize model\n",
        "model = Net(dtype=torch.float32).to(device)\n",
        "model = torch.compile(model)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVdyMEccACpc",
        "outputId": "1394dc94-8f4c-409d-97be-ac4ed1337f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10000, 32, 4096]) torch.Size([10000, 32, 1])\n",
            "2.6152403354644775 [[1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ],
      "source": [
        "# Generate synthetic data\n",
        "B = 32\n",
        "N = B * 10000\n",
        "\n",
        "X = torch.randn(N // B, B, n_features, device=device, dtype=torch.float32).to(device)\n",
        "Y = torch.randint(0, 2, (N // B, B, 1), device=device, dtype=torch.long).to(device)\n",
        "print(X.shape, Y.shape)\n",
        "print(X[0,0,0].item(), Y[0,:5,:].cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kYb8iqqVACpc"
      },
      "outputs": [],
      "source": [
        "@torch.compile\n",
        "def train_step(model, optimizer, X, Y, i):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    x, y = X[i], Y[i]\n",
        "    logits = model(x)\n",
        "    loss = F.cross_entropy(logits.view(-1, 2), y.view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePdGh52KACpc",
        "outputId": "cb3a5115-dfa6-4e59-d909-1e053f4be530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Iter: 9999, Loss: 0.6934, Iter time: 3.3634 ms\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "num_epochs = 1\n",
        "torch.cuda.synchronize()  # Ensure GPU is synchronized before timing\n",
        "\n",
        "avg_iter_time = -1\n",
        "\n",
        "model.train()\n",
        "for e in range(num_epochs):\n",
        "    for i in range(N // B):\n",
        "        start = time.time()\n",
        "\n",
        "        loss = train_step(model, optimizer, X, Y, i)\n",
        "        torch.cuda.synchronize()  # Ensure computation is complete before timing\n",
        "\n",
        "        if avg_iter_time == -1:\n",
        "            avg_iter_time = (time.time() - start) * 1000\n",
        "        else:\n",
        "            avg_iter_time = (avg_iter_time * i + (time.time() - start) * 1000) / (i + 1)\n",
        "\n",
        "        print(f\"Epoch: {e}, Iter: {i}, Loss: {loss:.4f}, Iter time: {avg_iter_time:.4f} ms\")\n",
        "        clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "baELOI75DWOs"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "project",
      "language": "python",
      "name": "project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
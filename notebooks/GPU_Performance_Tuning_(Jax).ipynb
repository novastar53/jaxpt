{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPsSGOtRBK0amadyQGdFkC4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/novastar53/jaxpt/blob/dev/notebooks/GPU_Performance_Tuning_(Jax).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elwUt1L7ARsB"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax import nnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Hardware setup\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Available devices:\", jax.devices())\n",
        "\n",
        "jax.config.update(\"jax_platform_name\", \"gpu\") # Make sure we're using the GPU\n",
        "#jax.config.update(\"jax_enable_x64\", True) # Make sure the highest precision is enabled in case we need\n",
        "jax.config.update(\"jax_default_matmul_precision\", \"bfloat16\") # Set the default precision for matrix multiplication\n",
        "\n",
        "#os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"1\"\n",
        "#os.environ[\"JAX_ENABLE_X64\"] = \"False\"\n",
        "\n",
        "print(\"Using device:\", jax.default_backend())  # Should print 'gpu'\n",
        "\n",
        "A = jnp.array(np.random.normal(size=(4096, 4096)), dtype=jnp.float32) # Makes sure the matmul is fast\n",
        "\n",
        "%timeit (A@A).block_until_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzl5YtV-AXuY",
        "outputId": "acd93bf2-0d42-4eca-c52d-f98bb43da3d9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX version: 0.4.33\n",
            "Available devices: [CpuDevice(id=0)]\n",
            "Using device: cpu\n",
            "587 ms ± 29.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 4096\n",
        "\n",
        "class Net(nnx.Module):\n",
        "\n",
        "  def __init__(self, dtype: jnp.dtype, rngs: nnx.Rngs):\n",
        "    self.layer1 = nnx.Linear(n_features, n_features, dtype=dtype, rngs=rngs)\n",
        "    self.layer2 = nnx.Linear(n_features, n_features, dtype=dtype, rngs=rngs)\n",
        "    self.layer3 = nnx.Linear(n_features, n_features, dtype=dtype, rngs=rngs)\n",
        "    self.out = nnx.Linear(n_features, 2, dtype=dtype, rngs=rngs)\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = nnx.gelu(self.layer1(x), approximate=True)\n",
        "    x = nnx.gelu(self.layer2(x), approximate=True)\n",
        "    x = nnx.gelu(self.layer3(x), approximate=True)\n",
        "    y = self.out(x)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "ZPB2KgtDAbhJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.PRNGKey(0)\n",
        "rngs = nnx.Rngs(key)\n",
        "m = Net(dtype=jnp.float32, rngs=rngs)"
      ],
      "metadata": {
        "id": "joJYONoFGXrz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B = 32\n",
        "N = B*10000\n",
        "\n",
        "X = jax.random.normal(key=key, shape=(N, n_features), dtype=jnp.float32).reshape(N // B, B, n_features)\n",
        "Y = jax.random.randint(key=key, shape=(N, 1), minval=0, maxval=2, dtype=jnp.int8).reshape( N // B, B, 1)\n",
        "print(X.shape, Y.shape)\n",
        "print(X[0,0,0], Y[0,:5, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jie6tebKHgLX",
        "outputId": "4b59b8be-cb78-477d-88b2-b32dd6f02d0b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 4096) (10000, 32, 1)\n",
            "-0.05067226 [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = nnx.Optimizer(m, optax.adamw(3e-4))"
      ],
      "metadata": {
        "id": "jPAFB_a0IG1d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@nnx.jit\n",
        "def train_step(model, optimizer, batch, targets):\n",
        "\n",
        "    def loss_fn(model, batch, targets):\n",
        "        logits = model(batch)\n",
        "        loss = optax.softmax_cross_entropy(logits, targets).mean()\n",
        "        return loss\n",
        "\n",
        "    loss, grads =  nnx.value_and_grad(loss_fn)(model, batch, targets)\n",
        "    optimizer.update(grads)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "3pdLtKmil3x2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "avg_iter_time = -1\n",
        "for e in range(num_epochs):\n",
        "  for i in range( N // B ):\n",
        "    start = time.time()\n",
        "    x, y = X[i,...], Y[i,...]\n",
        "    loss = train_step(m, optimizer, x, y)\n",
        "    jax.block_until_ready(loss)\n",
        "    if avg_iter_time == -1:\n",
        "      avg_iter_time = (time.time() - start)*1000\n",
        "    else:\n",
        "      avg_iter_time = (avg_iter_time * i + (time.time() - start)*1000) / (i + 1)\n",
        "    print(f\"Epoch: {e}, Iter: {i}, Loss: {loss:0.4f}, Iter time: {avg_iter_time:0.4f} ms\")\n",
        "    clear_output(wait=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZM2ESWPSmKm9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "f0305ecd-68bf-4224-eb02-ccaf4f5ed283"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7ddacde6a2f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_until_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mavg_iter_time\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mavg_iter_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mblock_until_ready\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2952\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;31m# Fast path for single array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2954\u001b[0;31m     \u001b[0mtry_to_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2955\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m     \u001b[0;31m# Optimized for multiple arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mtry_to_block\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2935\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtry_to_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_until_ready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6QAklFL9rmcK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPSgJopi3vZzBq0XYe4ojTK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/novastar53/jaxpt/blob/dev/notebooks/GPU_Performance_Tuning_(Jax).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "elwUt1L7ARsB"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax import nnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Hardware setup\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Available devices:\", jax.devices())\n",
        "\n",
        "jax.config.update(\"jax_platform_name\", \"gpu\") # Make sure we're using the GPU\n",
        "#jax.config.update(\"jax_enable_x64\", True) # Make sure the highest precision is enabled in case we need\n",
        "jax.config.update(\"jax_default_matmul_precision\", \"float32\") # Set the default precision for matrix multiplication\n",
        "\n",
        "#os.environ[\"NVIDIA_TF32_OVERRIDE\"] = \"1\"\n",
        "#os.environ[\"JAX_ENABLE_X64\"] = \"False\"\n",
        "\n",
        "print(\"Using device:\", jax.default_backend())  # Should print 'gpu'\n",
        "\n",
        "A = jnp.array(np.random.normal(size=(4096, 4096)), dtype=jnp.float32) # Makes sure the matmul is fast\n",
        "\n",
        "%timeit (A@A).block_until_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzl5YtV-AXuY",
        "outputId": "86510a78-8cd7-472d-a56d-19c7757e49e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX version: 0.4.33\n",
            "Available devices: [CudaDevice(id=0)]\n",
            "Using device: gpu\n",
            "9.53 ms ± 36.6 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 8196\n",
        "\n",
        "class Net(nnx.Module):\n",
        "\n",
        "  def __init__(self, dtype: jnp.dtype, rngs: nnx.Rngs):\n",
        "    self.layer1 = nnx.Linear(n_features, n_features, dtype=dtype, rngs=rngs)\n",
        "    self.layer2 = nnx.Linear(n_features, n_features, dtype=dtype, rngs=rngs)\n",
        "    self.layer3 = nnx.Linear(n_features, n_features, dtype=dtype, rngs=rngs)\n",
        "    self.out = nnx.Linear(n_features, 2, dtype=dtype, rngs=rngs)\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = nnx.gelu(self.layer1(x), approximate=True)\n",
        "    x = nnx.gelu(self.layer2(x), approximate=True)\n",
        "    x = nnx.gelu(self.layer3(x), approximate=True)\n",
        "    y = self.out(x)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "ZPB2KgtDAbhJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.PRNGKey(0)\n",
        "rngs = nnx.Rngs(key)\n",
        "m = Net(dtype=jnp.float32, rngs=rngs)"
      ],
      "metadata": {
        "id": "joJYONoFGXrz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B = 32\n",
        "N = B*10000\n",
        "\n",
        "X = jax.random.normal(key=key, shape=(N, n_features), dtype=jnp.float32).reshape(N // B, B, n_features)\n",
        "Y = jax.random.randint(key=key, shape=(N, 1), minval=0, maxval=2, dtype=jnp.int8).reshape( N // B, B, 1)\n",
        "print(X.shape, Y.shape)\n",
        "print(X[0,0,0], Y[0,:5, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jie6tebKHgLX",
        "outputId": "1f143271-bf80-48f3-f67d-69ebbe7ce4c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 8196) (10000, 32, 1)\n",
            "-0.44350547 [[0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = nnx.Optimizer(m, optax.adamw(3e-4))"
      ],
      "metadata": {
        "id": "jPAFB_a0IG1d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@nnx.jit\n",
        "def train_step(model, optimizer, batch, targets):\n",
        "\n",
        "    def loss_fn(model, batch, targets):\n",
        "        logits = model(batch)\n",
        "        loss = optax.softmax_cross_entropy(logits, targets).mean()\n",
        "        return loss\n",
        "\n",
        "    loss, grads =  nnx.value_and_grad(loss_fn)(model, batch, targets)\n",
        "    optimizer.update(grads)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "3pdLtKmil3x2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "avg_iter_time = -1\n",
        "for e in range(num_epochs):\n",
        "  for i in range( N // B ):\n",
        "    start = time.time()\n",
        "    x, y = X[i,...], Y[i,...]\n",
        "    loss = train_step(m, optimizer, x, y)\n",
        "    jax.block_until_ready(loss)\n",
        "    if avg_iter_time == -1:\n",
        "      avg_iter_time = (time.time() - start)*1000\n",
        "    else:\n",
        "      avg_iter_time = (avg_iter_time * i + (time.time() - start)*1000) / (i + 1)\n",
        "    print(f\"Epoch: {e}, Iter: {i}, Loss: {loss:0.4f}, Iter time: {avg_iter_time:0.4f} ms\")\n",
        "    clear_output(wait=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZM2ESWPSmKm9",
        "outputId": "936241d8-4bd5-4b9f-ec6e-b58f1086e8cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Iter: 9999, Loss: 0.7368, Iter time: 8.9720 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6QAklFL9rmcK"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}